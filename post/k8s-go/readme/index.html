<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title> - 爱像水墨青花</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="lflxp" /><meta name="description" content="目录 这里整理了我学习Kubernetes的资料，供大家参考交流
 安装  离线环境二进制方式安装Kubernetes集群)   概念  Kubernetes的Controllers Kubernetes的命名空间 Kubernetes Pod详细介绍 Kubernetes 存储系统介绍 Kubernetes 中的ConfigMap和Secret   案例  Kubernetes部署ELK并且使用Filebeat收集集群容器日志    kubeadm安装kubernetes V1.11.1 集群  之前测试了离线环境下使用二进制方法安装配置Kubernetes集群的方法，安装的过程中听说 kubeadm 安装配置集群更加方便，因此试着折腾了一下。安装过程中，也有一些坑，相对来说操作上要比二进制方便一点，毕竟不用手工创建那么多的配置文件，但是对于了解Kubernetes的运作方式，可能不如二进制方式好。同时，因为kubeadm方式，很多集群依赖的组件都是以容器方式运行在Master节点上，感觉对于虚拟机资源的消耗要比二进制方式厉害。
 0. kubeadm 介绍与准备工作  kubeadm is designed to be a simple way for new users to start trying Kubernetes out, possibly for the first time, a way for existing users to test their application on and stitch together a cluster easily, and also to be a building block in other ecosystem and/or installer tool with a larger scope." /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.62.2 with theme even" />


<link rel="canonical" href="https://www.lflxp.cn/post/k8s-go/readme/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="" />
<meta property="og:description" content="目录 这里整理了我学习Kubernetes的资料，供大家参考交流
 安装  离线环境二进制方式安装Kubernetes集群)   概念  Kubernetes的Controllers Kubernetes的命名空间 Kubernetes Pod详细介绍 Kubernetes 存储系统介绍 Kubernetes 中的ConfigMap和Secret   案例  Kubernetes部署ELK并且使用Filebeat收集集群容器日志    kubeadm安装kubernetes V1.11.1 集群  之前测试了离线环境下使用二进制方法安装配置Kubernetes集群的方法，安装的过程中听说 kubeadm 安装配置集群更加方便，因此试着折腾了一下。安装过程中，也有一些坑，相对来说操作上要比二进制方便一点，毕竟不用手工创建那么多的配置文件，但是对于了解Kubernetes的运作方式，可能不如二进制方式好。同时，因为kubeadm方式，很多集群依赖的组件都是以容器方式运行在Master节点上，感觉对于虚拟机资源的消耗要比二进制方式厉害。
 0. kubeadm 介绍与准备工作  kubeadm is designed to be a simple way for new users to start trying Kubernetes out, possibly for the first time, a way for existing users to test their application on and stitch together a cluster easily, and also to be a building block in other ecosystem and/or installer tool with a larger scope." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.lflxp.cn/post/k8s-go/readme/" />

<meta itemprop="name" content="">
<meta itemprop="description" content="目录 这里整理了我学习Kubernetes的资料，供大家参考交流
 安装  离线环境二进制方式安装Kubernetes集群)   概念  Kubernetes的Controllers Kubernetes的命名空间 Kubernetes Pod详细介绍 Kubernetes 存储系统介绍 Kubernetes 中的ConfigMap和Secret   案例  Kubernetes部署ELK并且使用Filebeat收集集群容器日志    kubeadm安装kubernetes V1.11.1 集群  之前测试了离线环境下使用二进制方法安装配置Kubernetes集群的方法，安装的过程中听说 kubeadm 安装配置集群更加方便，因此试着折腾了一下。安装过程中，也有一些坑，相对来说操作上要比二进制方便一点，毕竟不用手工创建那么多的配置文件，但是对于了解Kubernetes的运作方式，可能不如二进制方式好。同时，因为kubeadm方式，很多集群依赖的组件都是以容器方式运行在Master节点上，感觉对于虚拟机资源的消耗要比二进制方式厉害。
 0. kubeadm 介绍与准备工作  kubeadm is designed to be a simple way for new users to start trying Kubernetes out, possibly for the first time, a way for existing users to test their application on and stitch together a cluster easily, and also to be a building block in other ecosystem and/or installer tool with a larger scope.">

<meta itemprop="wordCount" content="1367">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="目录 这里整理了我学习Kubernetes的资料，供大家参考交流
 安装  离线环境二进制方式安装Kubernetes集群)   概念  Kubernetes的Controllers Kubernetes的命名空间 Kubernetes Pod详细介绍 Kubernetes 存储系统介绍 Kubernetes 中的ConfigMap和Secret   案例  Kubernetes部署ELK并且使用Filebeat收集集群容器日志    kubeadm安装kubernetes V1.11.1 集群  之前测试了离线环境下使用二进制方法安装配置Kubernetes集群的方法，安装的过程中听说 kubeadm 安装配置集群更加方便，因此试着折腾了一下。安装过程中，也有一些坑，相对来说操作上要比二进制方便一点，毕竟不用手工创建那么多的配置文件，但是对于了解Kubernetes的运作方式，可能不如二进制方式好。同时，因为kubeadm方式，很多集群依赖的组件都是以容器方式运行在Master节点上，感觉对于虚拟机资源的消耗要比二进制方式厉害。
 0. kubeadm 介绍与准备工作  kubeadm is designed to be a simple way for new users to start trying Kubernetes out, possibly for the first time, a way for existing users to test their application on and stitch together a cluster easily, and also to be a building block in other ecosystem and/or installer tool with a larger scope."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">琵琶</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">主页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">琵琶</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">主页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title"></h1>

      <div class="post-meta">
        <span class="post-time"> 0001-01-01 </span>
        
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#0-kubeadm-介绍与准备工作">0. kubeadm 介绍与准备工作</a>
      <ul>
        <li><a href="#01-关掉-selinux">0.1 关掉 selinux</a></li>
        <li><a href="#02-关掉防火墙">0.2 关掉防火墙</a></li>
        <li><a href="#03-关闭-swap">0.3 关闭 swap</a></li>
        <li><a href="#04-配置转发参数">0.4 配置转发参数</a></li>
        <li><a href="#05-设置国内-yum-源">0.5 设置国内 yum 源</a></li>
        <li><a href="#06-安装一些必备的工具">0.6 安装一些必备的工具</a></li>
      </ul>
    </li>
    <li><a href="#1-安装-kubeadm-必须的软件在所有节点上运行">1. 安装 kubeadm 必须的软件，在所有节点上运行</a>
      <ul>
        <li><a href="#11-安装docker">1.1 安装Docker</a></li>
        <li><a href="#12-安装kubeadmkubectlkubelet">1.2 安装kubeadm、kubectl、kubelet</a></li>
      </ul>
    </li>
    <li><a href="#2-安装master节点">2. 安装Master节点</a></li>
    <li><a href="#3-master节点的网络配置">3. Master节点的网络配置</a></li>
    <li><a href="#4-加入节点">4. 加入节点</a></li>
    <li><a href="#x-坑">X. 坑</a>
      <ul>
        <li><a href="#pause31">pause:3.1</a></li>
        <li><a href="#两台服务器时间不同步">两台服务器时间不同步。</a></li>
      </ul>
    </li>
    <li><a href="#参考资料">参考资料</a></li>
  </ul>
</nav>
  </div>
</div>
  <div class="post-outdated">
    <div class="warn">
      <p>【注意】最后更新于 <span class="timeago" datetime="0001-01-01T00:00:00" title="January 1, 0001">January 1, 0001</span>，文中内容可能已过时，请谨慎使用。</p>
    </div>
  </div>
    <div class="post-content">
      <h1 id="目录">目录</h1>
<p>这里整理了我学习Kubernetes的资料，供大家参考交流</p>
<ul>
<li>安装
<ul>
<li><a href="https://github.com/cocowool/k8s-go/blob/master/install/offline-binary.md">离线环境二进制方式安装Kubernetes集群</a>)</li>
</ul>
</li>
<li>概念
<ul>
<li><a href="https://github.com/cocowool/k8s-go/blob/master/controller/README.md">Kubernetes的Controllers</a></li>
<li><a href="https://github.com/cocowool/k8s-go/blob/master/learnrecord/namespace.MD">Kubernetes的命名空间</a></li>
<li><a href="https://github.com/cocowool/k8s-go/tree/master/pod">Kubernetes Pod详细介绍</a></li>
<li><a href="https://github.com/cocowool/k8s-go/tree/master/storage">Kubernetes 存储系统介绍</a></li>
<li><a href="https://github.com/cocowool/k8s-go/tree/master/storage/configmap.md">Kubernetes 中的ConfigMap和Secret</a></li>
</ul>
</li>
<li>案例
<ul>
<li><a href="https://github.com/cocowool/k8s-go/tree/master/elk">Kubernetes部署ELK并且使用Filebeat收集集群容器日志</a></li>
</ul>
</li>
</ul>
<h1 id="kubeadm安装kubernetes-v1111-集群">kubeadm安装kubernetes V1.11.1 集群</h1>
<blockquote>
<p>之前测试了<a href="https://www.cnblogs.com/cocowool/p/install_k8s_offline.html">离线环境下使用二进制方法安装配置Kubernetes集群</a>的方法，安装的过程中听说 kubeadm 安装配置集群更加方便，因此试着折腾了一下。安装过程中，也有一些坑，相对来说操作上要比二进制方便一点，毕竟不用手工创建那么多的配置文件，但是对于了解Kubernetes的运作方式，可能不如二进制方式好。同时，因为kubeadm方式，很多集群依赖的组件都是以容器方式运行在Master节点上，感觉对于虚拟机资源的消耗要比二进制方式厉害。</p>
</blockquote>
<h2 id="0-kubeadm-介绍与准备工作">0. kubeadm 介绍与准备工作</h2>
<blockquote>
<p>kubeadm is designed to be a simple way for new users to start trying Kubernetes out, possibly for the first time, a way for existing users to test their application on and stitch together a cluster easily, and also to be a building block in other ecosystem and/or installer tool with a larger scope.
kubeadm是一个python写的项目，代码在<a href="https://github.com/kubernetes/kubeadm">这里</a>，用来帮助快速部署Kubernetes集群环境，但是目前仅仅是作为测试环境使用，如果你想在生产环境使用，可是要三思。</p>
</blockquote>
<p>本文所用的环境：</p>
<ul>
<li>虚拟机软件：VirtualBox</li>
<li>操作系统：Centos 7.3 minimal 安装</li>
<li>网卡：两块网卡，一块 Host-Only方式，一块 Nat 方式。</li>
<li>网络规划：
<ul>
<li>Master:192.168.0.101</li>
<li>Node:192.168.0.102-104</li>
</ul>
</li>
</ul>
<h3 id="01-关掉-selinux">0.1 关掉 selinux</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ setenforce  <span class="m">0</span> 
$ sed -i <span class="s2">&#34;s/^SELINUX=enforcing/SELINUX=disabled/g&#34;</span> /etc/sysconfig/selinux 
</code></pre></td></tr></table>
</div>
</div><h3 id="02-关掉防火墙">0.2 关掉防火墙</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ systemctl stop firewalld
$ systemctl disable firewalld
</code></pre></td></tr></table>
</div>
</div><h3 id="03-关闭-swap">0.3 关闭 swap</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ swapoff -a 
$ sed -i <span class="s1">&#39;s/.*swap.*/#&amp;/&#39;</span> /etc/fstab
</code></pre></td></tr></table>
</div>
</div><h3 id="04-配置转发参数">0.4 配置转发参数</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ cat <span class="s">&lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf
</span><span class="s">net.bridge.bridge-nf-call-ip6tables = 1
</span><span class="s">net.bridge.bridge-nf-call-iptables = 1
</span><span class="s">EOF</span>
$ sysctl --system
</code></pre></td></tr></table>
</div>
</div><h3 id="05-设置国内-yum-源">0.5 设置国内 yum 源</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ cat <span class="s">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span><span class="s">[kubernetes]
</span><span class="s">name=Kubernetes
</span><span class="s">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
</span><span class="s">enabled=1
</span><span class="s">gpgcheck=1
</span><span class="s">repo_gpgcheck=1
</span><span class="s">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span><span class="s">EOF</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="06-安装一些必备的工具">0.6 安装一些必备的工具</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ yum install -y epel-release 
$ yum install -y net-tools wget vim  ntpdate
</code></pre></td></tr></table>
</div>
</div><h2 id="1-安装-kubeadm-必须的软件在所有节点上运行">1. 安装 kubeadm 必须的软件，在所有节点上运行</h2>
<h3 id="11-安装docker">1.1 安装Docker</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ yum install -y docker
$ systemctl <span class="nb">enable</span> docker <span class="o">&amp;&amp;</span> systemctl start docker
$ <span class="c1">#设置系统服务，如果不设置后面 kubeadm init 的时候会有 warning</span>
$ systemctl <span class="nb">enable</span> docker.service
</code></pre></td></tr></table>
</div>
</div><p>如果想要用二进制方法安装最新版本的Docker，可以参考我之前的文章<a href="https://www.cnblogs.com/cocowool/p/install_docker_ce_in_redhat_73.html">在Redhat 7.3中采用离线方式安装Docker</a></p>
<h3 id="12-安装kubeadmkubectlkubelet">1.2 安装kubeadm、kubectl、kubelet</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ yum install -y kubelet kubeadm kubectl kubernetes-cni
$ systemctl <span class="nb">enable</span> kubelet <span class="o">&amp;&amp;</span> systemctl start kubelet
</code></pre></td></tr></table>
</div>
</div><p>这一步之后kubelet还不能正常运行，还处于下面的状态。</p>
<blockquote>
<p>The kubelet is now restarting every few seconds, as it waits in a crashloop for kubeadm to tell it what to do.</p>
</blockquote>
<h2 id="2-安装master节点">2. 安装Master节点</h2>
<p>因为国内没办法访问Google的镜像源，变通的方法是从其他镜像源下载后，修改tag。执行下面这个Shell脚本即可。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh"><span class="cp">#!/bin/bash
</span><span class="cp"></span><span class="nv">images</span><span class="o">=</span><span class="o">(</span>kube-proxy-amd64:v1.11.0 kube-scheduler-amd64:v1.11.0 kube-controller-manager-amd64:v1.11.0 kube-apiserver-amd64:v1.11.0
etcd-amd64:3.2.18 coredns:1.1.3 pause-amd64:3.1 kubernetes-dashboard-amd64:v1.8.3 k8s-dns-sidecar-amd64:1.14.9 k8s-dns-kube-dns-amd64:1.14.9
k8s-dns-dnsmasq-nanny-amd64:1.14.9 <span class="o">)</span>
<span class="k">for</span> imageName in <span class="si">${</span><span class="nv">images</span><span class="p">[@]</span><span class="si">}</span> <span class="p">;</span> <span class="k">do</span>
  docker pull registry.cn-hangzhou.aliyuncs.com/k8sth/<span class="nv">$imageName</span>
  docker tag registry.cn-hangzhou.aliyuncs.com/k8sth/<span class="nv">$imageName</span> k8s.gcr.io/<span class="nv">$imageName</span>
  <span class="c1">#docker rmi registry.cn-hangzhou.aliyuncs.com/k8sth/$imageName</span>
<span class="k">done</span>
docker tag da86e6ba6ca1 k8s.gcr.io/pause:3.1
</code></pre></td></tr></table>
</div>
</div><p>接下来执行Master节点的初始化，因为我的虚拟机是双网卡，需要指定apiserver的监听地址。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh"><span class="o">[</span>root@devops-101 ~<span class="o">]</span><span class="c1"># kubeadm init --kubernetes-version=v1.11.0 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.0.101</span>
<span class="o">[</span>init<span class="o">]</span> using Kubernetes version: v1.11.0
<span class="o">[</span>preflight<span class="o">]</span> running pre-flight checks
I0724 08:36:35.636931    <span class="m">3409</span> kernel_validator.go:81<span class="o">]</span> Validating kernel version
I0724 08:36:35.637052    <span class="m">3409</span> kernel_validator.go:96<span class="o">]</span> Validating kernel config
	<span class="o">[</span>WARNING Hostname<span class="o">]</span>: hostname <span class="s2">&#34;devops-101&#34;</span> could not be reached
	<span class="o">[</span>WARNING Hostname<span class="o">]</span>: hostname <span class="s2">&#34;devops-101&#34;</span> lookup devops-101 on 172.20.10.1:53: no such host
	<span class="o">[</span>WARNING Service-Kubelet<span class="o">]</span>: kubelet service is not enabled, please run <span class="s1">&#39;systemctl enable kubelet.service&#39;</span>
<span class="o">[</span>preflight/images<span class="o">]</span> Pulling images required <span class="k">for</span> setting up a Kubernetes cluster
<span class="o">[</span>preflight/images<span class="o">]</span> This might take a minute or two, depending on the speed of your internet connection
<span class="o">[</span>preflight/images<span class="o">]</span> You can also perform this action in beforehand using <span class="s1">&#39;kubeadm config images pull&#39;</span>
<span class="o">[</span>kubelet<span class="o">]</span> Writing kubelet environment file with flags to file <span class="s2">&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
<span class="o">[</span>kubelet<span class="o">]</span> Writing kubelet configuration to file <span class="s2">&#34;/var/lib/kubelet/config.yaml&#34;</span>
<span class="o">[</span>preflight<span class="o">]</span> Activating the kubelet service
<span class="o">[</span>certificates<span class="o">]</span> Generated ca certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> Generated apiserver certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> apiserver serving cert is signed <span class="k">for</span> DNS names <span class="o">[</span>devops-101 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local<span class="o">]</span> and IPs <span class="o">[</span>10.96.0.1 192.168.0.101<span class="o">]</span>
<span class="o">[</span>certificates<span class="o">]</span> Generated apiserver-kubelet-client certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> Generated sa key and public key.
<span class="o">[</span>certificates<span class="o">]</span> Generated front-proxy-ca certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> Generated front-proxy-client certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> Generated etcd/ca certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> Generated etcd/server certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> etcd/server serving cert is signed <span class="k">for</span> DNS names <span class="o">[</span>devops-101 localhost<span class="o">]</span> and IPs <span class="o">[</span>127.0.0.1 ::1<span class="o">]</span>
<span class="o">[</span>certificates<span class="o">]</span> Generated etcd/peer certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> etcd/peer serving cert is signed <span class="k">for</span> DNS names <span class="o">[</span>devops-101 localhost<span class="o">]</span> and IPs <span class="o">[</span>192.168.0.101 127.0.0.1 ::1<span class="o">]</span>
<span class="o">[</span>certificates<span class="o">]</span> Generated etcd/healthcheck-client certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> Generated apiserver-etcd-client certificate and key.
<span class="o">[</span>certificates<span class="o">]</span> valid certificates and keys now exist in <span class="s2">&#34;/etc/kubernetes/pki&#34;</span>
<span class="o">[</span>kubeconfig<span class="o">]</span> Wrote KubeConfig file to disk: <span class="s2">&#34;/etc/kubernetes/admin.conf&#34;</span>
<span class="o">[</span>kubeconfig<span class="o">]</span> Wrote KubeConfig file to disk: <span class="s2">&#34;/etc/kubernetes/kubelet.conf&#34;</span>
<span class="o">[</span>kubeconfig<span class="o">]</span> Wrote KubeConfig file to disk: <span class="s2">&#34;/etc/kubernetes/controller-manager.conf&#34;</span>
<span class="o">[</span>kubeconfig<span class="o">]</span> Wrote KubeConfig file to disk: <span class="s2">&#34;/etc/kubernetes/scheduler.conf&#34;</span>
<span class="o">[</span>controlplane<span class="o">]</span> wrote Static Pod manifest <span class="k">for</span> component kube-apiserver to <span class="s2">&#34;/etc/kubernetes/manifests/kube-apiserver.yaml&#34;</span>
<span class="o">[</span>controlplane<span class="o">]</span> wrote Static Pod manifest <span class="k">for</span> component kube-controller-manager to <span class="s2">&#34;/etc/kubernetes/manifests/kube-controller-manager.yaml&#34;</span>
<span class="o">[</span>controlplane<span class="o">]</span> wrote Static Pod manifest <span class="k">for</span> component kube-scheduler to <span class="s2">&#34;/etc/kubernetes/manifests/kube-scheduler.yaml&#34;</span>
<span class="o">[</span>etcd<span class="o">]</span> Wrote Static Pod manifest <span class="k">for</span> a <span class="nb">local</span> etcd instance to <span class="s2">&#34;/etc/kubernetes/manifests/etcd.yaml&#34;</span>
<span class="o">[</span>init<span class="o">]</span> waiting <span class="k">for</span> the kubelet to boot up the control plane as Static Pods from directory <span class="s2">&#34;/etc/kubernetes/manifests&#34;</span> 
<span class="o">[</span>init<span class="o">]</span> this might take a minute or longer <span class="k">if</span> the control plane images have to be pulled
<span class="o">[</span>apiclient<span class="o">]</span> All control plane components are healthy after 46.002877 seconds
<span class="o">[</span>uploadconfig<span class="o">]</span> storing the configuration used in ConfigMap <span class="s2">&#34;kubeadm-config&#34;</span> in the <span class="s2">&#34;kube-system&#34;</span> Namespace
<span class="o">[</span>kubelet<span class="o">]</span> Creating a ConfigMap <span class="s2">&#34;kubelet-config-1.11&#34;</span> in namespace kube-system with the configuration <span class="k">for</span> the kubelets in the cluster
<span class="o">[</span>markmaster<span class="o">]</span> Marking the node devops-101 as master by adding the label <span class="s2">&#34;node-role.kubernetes.io/master=&#39;&#39;&#34;</span>
<span class="o">[</span>markmaster<span class="o">]</span> Marking the node devops-101 as master by adding the taints <span class="o">[</span>node-role.kubernetes.io/master:NoSchedule<span class="o">]</span>
<span class="o">[</span>patchnode<span class="o">]</span> Uploading the CRI Socket information <span class="s2">&#34;/var/run/dockershim.sock&#34;</span> to the Node API object <span class="s2">&#34;devops-101&#34;</span> as an annotation
<span class="o">[</span>bootstraptoken<span class="o">]</span> using token: wkj0bo.pzibll6rd9gyi5z8
<span class="o">[</span>bootstraptoken<span class="o">]</span> configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order <span class="k">for</span> nodes to get long term certificate credentials
<span class="o">[</span>bootstraptoken<span class="o">]</span> configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
<span class="o">[</span>bootstraptoken<span class="o">]</span> configured RBAC rules to allow certificate rotation <span class="k">for</span> all node client certificates in the cluster
<span class="o">[</span>bootstraptoken<span class="o">]</span> creating the <span class="s2">&#34;cluster-info&#34;</span> ConfigMap in the <span class="s2">&#34;kube-public&#34;</span> namespace
<span class="o">[</span>addons<span class="o">]</span> Applied essential addon: CoreDNS
<span class="o">[</span>addons<span class="o">]</span> Applied essential addon: kube-proxy

Your Kubernetes master has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p <span class="nv">$HOME</span>/.kube
  sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
  sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config

You should now deploy a pod network to the cluster.
Run <span class="s2">&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join 192.168.0.101:6443 --token wkj0bo.pzibll6rd9gyi5z8 --discovery-token-ca-cert-hash sha256:51985223a369a1f8c226f3ccdcf97f4ad5ff201a7c8c708e1636eea0739c0f05
</code></pre></td></tr></table>
</div>
</div><p>看到以上信息表示Master节点已经初始化成功了。如果需要用普通用户管理集群，可以按照提示进行操作，如果是使用root用户管理，执行下面的命令。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh"><span class="o">[</span>root@devops-101 ~<span class="o">]</span><span class="c1"># export KUBECONFIG=/etc/kubernetes/admin.conf</span> 
<span class="o">[</span>root@devops-101 ~<span class="o">]</span><span class="c1"># kubectl get nodes</span>
NAME         STATUS     ROLES     AGE       VERSION
devops-101   NotReady   master    7m        v1.11.1
<span class="o">[</span>root@devops-101 ~<span class="o">]</span><span class="c1"># kubectl get pods --all-namespaces</span>
NAMESPACE     NAME                                 READY     STATUS    RESTARTS   AGE
kube-system   coredns-78fcdf6894-8sd6g             0/1       Pending   <span class="m">0</span>          7m
kube-system   coredns-78fcdf6894-lgvd9             0/1       Pending   <span class="m">0</span>          7m
kube-system   etcd-devops-101                      1/1       Running   <span class="m">0</span>          6m
kube-system   kube-apiserver-devops-101            1/1       Running   <span class="m">0</span>          6m
kube-system   kube-controller-manager-devops-101   1/1       Running   <span class="m">0</span>          6m
kube-system   kube-proxy-bhmj8                     1/1       Running   <span class="m">0</span>          7m
kube-system   kube-scheduler-devops-101            1/1       Running   <span class="m">0</span>          6m
</code></pre></td></tr></table>
</div>
</div><p>可以看到节点还没有Ready，dns的两个pod也没不正常，还需要安装网络配置。</p>
<h2 id="3-master节点的网络配置">3. Master节点的网络配置</h2>
<p>这里我选用了 Flannel 的方案。</p>
<blockquote>
<p>kubeadm only supports Container Network Interface (CNI) based networks (and does not support kubenet).</p>
</blockquote>
<p>修改系统设置，创建 flannel 网络。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh"><span class="o">[</span>root@devops-101 ~<span class="o">]</span><span class="c1"># sysctl net.bridge.bridge-nf-call-iptables=1</span>
net.bridge.bridge-nf-call-iptables <span class="o">=</span> <span class="m">1</span>
<span class="o">[</span>root@devops-101 ~<span class="o">]</span><span class="c1"># kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml</span>
clusterrole.rbac.authorization.k8s.io/flannel created
clusterrolebinding.rbac.authorization.k8s.io/flannel created
serviceaccount/flannel created
configmap/kube-flannel-cfg created
daemonset.extensions/kube-flannel-ds created
</code></pre></td></tr></table>
</div>
</div><p>flannel 默认会使用主机的第一张网卡，如果你有多张网卡，需要通过配置单独指定。修改 kube-flannel.yml 中的以下部分</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-yaml" data-lang="yaml">containers<span class="p">:</span><span class="w">
</span><span class="w">      </span>-<span class="w"> </span>name<span class="p">:</span><span class="w"> </span>kube-flannel<span class="w">
</span><span class="w">        </span>image<span class="p">:</span><span class="w"> </span>quay.io/coreos/flannel<span class="p">:</span>v0<span class="m">.10</span><span class="m">.0</span>-amd64<span class="w">
</span><span class="w">        </span>command<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>/opt/bin/flanneld<span class="w">
</span><span class="w">        </span>args<span class="p">:</span><span class="w">
</span><span class="w">        </span>-<span class="w"> </span>--ip-masq<span class="w">
</span><span class="w">        </span>-<span class="w"> </span>--kube-subnet-mgr<span class="w">
</span><span class="w">        </span>-<span class="w"> </span>--iface=enp0s3<span class="w">            </span><span class="c">#指定内网网卡</span><span class="w">
</span></code></pre></td></tr></table>
</div>
</div><p>执行成功后，Master并不能马上变成Ready状态，稍等几分钟，就可以看到所有状态都正常了。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh"><span class="o">[</span>root@devops-101 ~<span class="o">]</span><span class="c1"># kubectl get pods --all-namespaces</span>
NAMESPACE     NAME                                 READY     STATUS    RESTARTS   AGE
kube-system   coredns-78fcdf6894-8sd6g             1/1       Running   <span class="m">0</span>          14m
kube-system   coredns-78fcdf6894-lgvd9             1/1       Running   <span class="m">0</span>          14m
kube-system   etcd-devops-101                      1/1       Running   <span class="m">0</span>          13m
kube-system   kube-apiserver-devops-101            1/1       Running   <span class="m">0</span>          13m
kube-system   kube-controller-manager-devops-101   1/1       Running   <span class="m">0</span>          13m
kube-system   kube-flannel-ds-6zljr                1/1       Running   <span class="m">0</span>          48s
kube-system   kube-proxy-bhmj8                     1/1       Running   <span class="m">0</span>          14m
kube-system   kube-scheduler-devops-101            1/1       Running   <span class="m">0</span>          13m
<span class="o">[</span>root@devops-101 ~<span class="o">]</span><span class="c1"># kubectl get nodes</span>
NAME         STATUS    ROLES     AGE       VERSION
devops-101   Ready     master    14m       v1.11.1
</code></pre></td></tr></table>
</div>
</div><h2 id="4-加入节点">4. 加入节点</h2>
<p>Node节点的加入集群前，首先需要按照本文的第0节和第1节做好准备工作，然后下载镜像。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ docker pull registry.cn-hangzhou.aliyuncs.com/k8sth/kube-proxy-amd64:v1.11.0
$ docker pull registry.cn-hangzhou.aliyuncs.com/k8sth/pause-amd64:3.1
$ docker tag registry.cn-hangzhou.aliyuncs.com/k8sth/pause-amd64:3.1 k8s.gcr.io/pause-amd64:3.1
$ docker tag registry.cn-hangzhou.aliyuncs.com/k8sth/kube-proxy-amd64:v1.11.0 k8s.gcr.io/kube-proxy-amd64:v1.11.0
$ docker tag registry.cn-hangzhou.aliyuncs.com/k8sth/pause-amd64:3.1 k8s.gcr.io/pause:3.1
</code></pre></td></tr></table>
</div>
</div><p>最后再根据Master节点的提示加入集群。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ kubeadm join 192.168.0.101:6443 --token wkj0bo.pzibll6rd9gyi5z8 --discovery-token-ca-cert-hash sha256:51985223a369a1f8c226f3ccdcf97f4ad5ff201a7c8c708e1636eea0739c0f05
</code></pre></td></tr></table>
</div>
</div><p>节点的启动也需要一点时间，稍后再到Master上查看状态。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh"><span class="o">[</span>root@devops-101 ~<span class="o">]</span><span class="c1"># kubectl get nodes</span>
NAME         STATUS    ROLES     AGE       VERSION
devops-101   Ready     master    1h        v1.11.1
devops-102   Ready     &lt;none&gt;    11m       v1.11.1
</code></pre></td></tr></table>
</div>
</div><p>我把安装中需要用到的一些命令整理成了几个脚本，放在我的<a href="https://github.com/cocowool/k8s-go">Github</a>上，大家可以下载使用。</p>
<p><img src="https://images2018.cnblogs.com/blog/39469/201807/39469-20180710163655709-89635310.png" alt=""></p>
<h2 id="x-坑">X. 坑</h2>
<h3 id="pause31">pause:3.1</h3>
<p>安装的过程中，发现kubeadmin会找 pause:3.1 的镜像，所以需要重新 tag 。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ docker tag registry.cn-hangzhou.aliyuncs.com/k8sth/pause-amd64:3.1 k8s.gcr.io/pause:3.1
</code></pre></td></tr></table>
</div>
</div><h3 id="两台服务器时间不同步">两台服务器时间不同步。</h3>
<p>报错信息</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh"><span class="o">[</span>discovery<span class="o">]</span> Failed to request cluster info, will try again: <span class="o">[</span>Get https://192.168.0.101:6443/api/v1/namespaces/kube-public/configmaps/cluster-info: x509: certificate has expired or is not yet valid<span class="o">]</span>
</code></pre></td></tr></table>
</div>
</div><p>解决方法，设定一个时间服务器同步两台服务器的时间。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-sh" data-lang="sh">$ ntpdate ntp1.aliyun.com
</code></pre></td></tr></table>
</div>
</div><h2 id="参考资料">参考资料</h2>
<ol>
<li><a href="https://www.jianshu.com/p/9c7e1c957752">centos7.3 kubernetes/k8s 1.10 离线安装</a></li>
<li><a href="https://www.cnblogs.com/ericnie/p/7749588.html">Kubeadm安装Kubernetes环境</a></li>
<li><a href="https://www.assistanz.com/steps-to-install-kubernetes-cluster-manually-using-centos-7/">Steps to install kubernetes</a></li>
<li><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm/">kubeadm reference guide</a></li>
<li><a href="https://www.kubernetes.org.cn/3808.html">kubeadm安装Kubernetes V1.10集群详细文档</a></li>
<li><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file">kubeadm reference</a></li>
<li><a href="https://blog.csdn.net/zhongyuemengxiang/article/details/79121932">kubeadm搭建kubernetes1.7.5集群</a></li>
<li><a href="https://www.cnblogs.com/Leo_wl/p/8511902.html">安装部署 Kubernetes 集群</a></li>
<li><a href="https://www.cnblogs.com/chenzeyong/p/5951959.html">linux 命令 &mdash;- 同步当前服务器时间</a></li>
<li><a href="https://www.cnblogs.com/myzony/p/9298783.html#1.%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C">CentOS 7.4 安装 K8S v1.11.0 集群所遇到的问题</a></li>
<li><a href="https://blog.csdn.net/andriy_dangli/article/details/79269348">使用kubeadm部署kubernetes</a></li>
</ol>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">lflxp</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        0001-01-01
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      
      <nav class="post-nav">
        <a class="prev" href="/post/k8s-go/pod/readme/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default"></span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/k8s-go/statefulset/readme/">
            <span class="next-text nav-default"></span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="comments-gitment"></div>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/default.min.css" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/gitment.browser.min.js" crossorigin="anonymous"></script>
    <script type="text/javascript">
      var gitment = new Gitment({
        id: '0001-01-01 00:00:00 \x2b0000 UTC',
        title: '',
        link: decodeURI(location.href),
        desc: '目录 这里整理了我学习Kubernetes的资料，供大家参考交流\n 安装  离线环境二进制方式安装Kubernetes集群)   概念  Kubernetes的Controllers Kubernetes的命名空间 Kubernetes Pod详细介绍 Kubernetes 存储系统介绍 Kubernetes 中的ConfigMap和Secret   案例  Kubernetes部署ELK并且使用Filebeat收集集群容器日志    kubeadm安装kubernetes V1.11.1 集群  之前测试了离线环境下使用二进制方法安装配置Kubernetes集群的方法，安装的过程中听说 kubeadm 安装配置集群更加方便，因此试着折腾了一下。安装过程中，也有一些坑，相对来说操作上要比二进制方便一点，毕竟不用手工创建那么多的配置文件，但是对于了解Kubernetes的运作方式，可能不如二进制方式好。同时，因为kubeadm方式，很多集群依赖的组件都是以容器方式运行在Master节点上，感觉对于虚拟机资源的消耗要比二进制方式厉害。\n 0. kubeadm 介绍与准备工作  kubeadm is designed to be a simple way for new users to start trying Kubernetes out, possibly for the first time, a way for existing users to test their application on and stitch together a cluster easily, and also to be a building block in other ecosystem and\/or installer tool with a larger scope.',
        owner: 'lflxp',
        repo: 'https:\/\/github.com\/lflxp\/lflxp.github.com',
        oauth: {
          client_id: '',
          client_secret: ''
        }
      });
      gitment.render('comments-gitment');
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/imsun/gitment">comments powered by gitment.</a></noscript>

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:382023823@qq.com" class="iconfont icon-email" title="email"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-twitter" title="twitter"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-facebook" title="facebook"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-google" title="google"></a>
      <a href="https://github.com/lflxp" class="iconfont icon-github" title="github"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-weibo" title="weibo"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-douban" title="douban"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-pocket" title="pocket"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-instagram" title="instagram"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-gitlab" title="gitlab"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="https://www.lflxp.cn/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2016 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">lflxp.cn 版权所有 ICP证：<a href='http://www.beian.miit.gov.cn' target='_blank'>渝ICP备17011066号-1</a></span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.min.js" integrity="sha256-jwCP0NAdCBloaIWTWHmW4i3snUNMHUNO+jr9rYd2iOI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.locales.min.js" integrity="sha256-ZwofwC1Lf/faQCzN7nZtfijVV6hSwxjQMwXL4gn9qU8=" crossorigin="anonymous"></script>
  <script><!-- NOTE: timeago.js uses the language code format like "zh_CN" (underscore and case sensitive) -->
    var languageCode = "zh-cn".replace(/-/g, '_').replace(/_(.*)/, function ($0, $1) {return $0.replace($1, $1.toUpperCase());});
    timeago().render(document.querySelectorAll('.timeago'), languageCode);
    timeago.cancel();  
  </script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', '渝ICP备17011066号-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
