<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title> - 爱像水墨青花</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="lflxp" /><meta name="description" content="在CPP下使用TVM来部署mxnet模型（以Insightface为例） 自从AI被炒作以来，各个深度学习框架层出不穷。我们通常来讲，作为AI从业者，我们通常经历着标注-训练-部署的过程。其中部署是较为痛苦的工作，尤其是在跨平台如（移动端需要native对接的时候。）当然用于inference框架同样也是层出不穷。但是大多数框架框架往往性能都一般，或者缺少相关op，或者就是转换模型较为困难。TVM的出现很大程度上为模型部署带来了福音。
但是网上将用于TVM部署的教程还比较少，尤其是通过cpp和移动端部署。本文以Insightface Model Zoo中的MobileFaceNet为例，介绍一下如何编译Mxnet模型、在python下inference、在cpp下inference、对比人脸余弦距离、以及在android下的部署。
安装 TVM编译环境的安装需要LLVM编译器，可以简要遵循官方的教程。 official installation tutorial.
LLVM 7.0 可能会导致编译错误，推荐使用LLVM 6.0.1
编译模型 TVM使用了一系列的优化措施来优化计算图，当模型编译完之后会生成若干个编译好的文件。在编译前要指定预编译的平台、架构、指令集等参数。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  import numpy as np import nnvm.compiler import nnvm.testing import tvm from tvm.contrib import graph_runtime import mxnet as mx from mxnet import ndarray as nd prefix,epoch = &amp;#34;emore1&amp;#34;,0 sym, arg_params, aux_params = mx." /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.62.2 with theme even" />


<link rel="canonical" href="https://www.lflxp.cn/post/hyperdl-tutorial/5.%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2/%E5%9C%A8cpp%E4%B8%8B%E4%BD%BF%E7%94%A8tvm%E6%9D%A5%E9%83%A8%E7%BD%B2mxnet%E6%A8%A1%E5%9E%8B%E4%BB%A5insightface%E4%B8%BA%E4%BE%8B/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="" />
<meta property="og:description" content="在CPP下使用TVM来部署mxnet模型（以Insightface为例） 自从AI被炒作以来，各个深度学习框架层出不穷。我们通常来讲，作为AI从业者，我们通常经历着标注-训练-部署的过程。其中部署是较为痛苦的工作，尤其是在跨平台如（移动端需要native对接的时候。）当然用于inference框架同样也是层出不穷。但是大多数框架框架往往性能都一般，或者缺少相关op，或者就是转换模型较为困难。TVM的出现很大程度上为模型部署带来了福音。
但是网上将用于TVM部署的教程还比较少，尤其是通过cpp和移动端部署。本文以Insightface Model Zoo中的MobileFaceNet为例，介绍一下如何编译Mxnet模型、在python下inference、在cpp下inference、对比人脸余弦距离、以及在android下的部署。
安装 TVM编译环境的安装需要LLVM编译器，可以简要遵循官方的教程。 official installation tutorial.
LLVM 7.0 可能会导致编译错误，推荐使用LLVM 6.0.1
编译模型 TVM使用了一系列的优化措施来优化计算图，当模型编译完之后会生成若干个编译好的文件。在编译前要指定预编译的平台、架构、指令集等参数。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  import numpy as np import nnvm.compiler import nnvm.testing import tvm from tvm.contrib import graph_runtime import mxnet as mx from mxnet import ndarray as nd prefix,epoch = &#34;emore1&#34;,0 sym, arg_params, aux_params = mx." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.lflxp.cn/post/hyperdl-tutorial/5.%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2/%E5%9C%A8cpp%E4%B8%8B%E4%BD%BF%E7%94%A8tvm%E6%9D%A5%E9%83%A8%E7%BD%B2mxnet%E6%A8%A1%E5%9E%8B%E4%BB%A5insightface%E4%B8%BA%E4%BE%8B/" />

<meta itemprop="name" content="">
<meta itemprop="description" content="在CPP下使用TVM来部署mxnet模型（以Insightface为例） 自从AI被炒作以来，各个深度学习框架层出不穷。我们通常来讲，作为AI从业者，我们通常经历着标注-训练-部署的过程。其中部署是较为痛苦的工作，尤其是在跨平台如（移动端需要native对接的时候。）当然用于inference框架同样也是层出不穷。但是大多数框架框架往往性能都一般，或者缺少相关op，或者就是转换模型较为困难。TVM的出现很大程度上为模型部署带来了福音。
但是网上将用于TVM部署的教程还比较少，尤其是通过cpp和移动端部署。本文以Insightface Model Zoo中的MobileFaceNet为例，介绍一下如何编译Mxnet模型、在python下inference、在cpp下inference、对比人脸余弦距离、以及在android下的部署。
安装 TVM编译环境的安装需要LLVM编译器，可以简要遵循官方的教程。 official installation tutorial.
LLVM 7.0 可能会导致编译错误，推荐使用LLVM 6.0.1
编译模型 TVM使用了一系列的优化措施来优化计算图，当模型编译完之后会生成若干个编译好的文件。在编译前要指定预编译的平台、架构、指令集等参数。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  import numpy as np import nnvm.compiler import nnvm.testing import tvm from tvm.contrib import graph_runtime import mxnet as mx from mxnet import ndarray as nd prefix,epoch = &#34;emore1&#34;,0 sym, arg_params, aux_params = mx.">

<meta itemprop="wordCount" content="611">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="在CPP下使用TVM来部署mxnet模型（以Insightface为例） 自从AI被炒作以来，各个深度学习框架层出不穷。我们通常来讲，作为AI从业者，我们通常经历着标注-训练-部署的过程。其中部署是较为痛苦的工作，尤其是在跨平台如（移动端需要native对接的时候。）当然用于inference框架同样也是层出不穷。但是大多数框架框架往往性能都一般，或者缺少相关op，或者就是转换模型较为困难。TVM的出现很大程度上为模型部署带来了福音。
但是网上将用于TVM部署的教程还比较少，尤其是通过cpp和移动端部署。本文以Insightface Model Zoo中的MobileFaceNet为例，介绍一下如何编译Mxnet模型、在python下inference、在cpp下inference、对比人脸余弦距离、以及在android下的部署。
安装 TVM编译环境的安装需要LLVM编译器，可以简要遵循官方的教程。 official installation tutorial.
LLVM 7.0 可能会导致编译错误，推荐使用LLVM 6.0.1
编译模型 TVM使用了一系列的优化措施来优化计算图，当模型编译完之后会生成若干个编译好的文件。在编译前要指定预编译的平台、架构、指令集等参数。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  import numpy as np import nnvm.compiler import nnvm.testing import tvm from tvm.contrib import graph_runtime import mxnet as mx from mxnet import ndarray as nd prefix,epoch = &#34;emore1&#34;,0 sym, arg_params, aux_params = mx."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">琵琶</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">主页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">琵琶</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">主页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title"></h1>

      <div class="post-meta">
        <span class="post-time"> 0001-01-01 </span>
        
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#在cpp下使用tvm来部署mxnet模型以insightface为例">在CPP下使用TVM来部署mxnet模型（以Insightface为例）</a></li>
        <li><a href="#安装">安装</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
  <div class="post-outdated">
    <div class="warn">
      <p>【注意】最后更新于 <span class="timeago" datetime="0001-01-01T00:00:00" title="January 1, 0001">January 1, 0001</span>，文中内容可能已过时，请谨慎使用。</p>
    </div>
  </div>
    <div class="post-content">
      <h3 id="在cpp下使用tvm来部署mxnet模型以insightface为例">在CPP下使用TVM来部署mxnet模型（以Insightface为例）</h3>
<p>自从AI被炒作以来，各个深度学习框架层出不穷。我们通常来讲，作为AI从业者，我们通常经历着标注-训练-部署的过程。其中部署是较为痛苦的工作，尤其是在跨平台如（移动端需要native对接的时候。）当然用于inference框架同样也是层出不穷。但是大多数框架框架往往性能都一般，或者缺少相关op，或者就是转换模型较为困难。TVM的出现很大程度上为模型部署带来了福音。</p>
<p>但是网上将用于TVM部署的教程还比较少，尤其是通过cpp和移动端部署。本文以Insightface Model Zoo中的MobileFaceNet为例，介绍一下如何编译Mxnet模型、在python下inference、在cpp下inference、对比人脸余弦距离、以及在android下的部署。</p>
<h3 id="安装">安装</h3>
<p>TVM编译环境的安装需要LLVM编译器，可以简要遵循官方的教程。 <a href="https://docs.tvm.ai/install/from_source.html#build-the-shared-library">official installation tutorial</a>.</p>
<p>LLVM 7.0 可能会导致编译错误，推荐使用LLVM 6.0.1</p>
<h4 id="编译模型">编译模型</h4>
<p>TVM使用了一系列的优化措施来优化计算图，当模型编译完之后会生成若干个编译好的文件。在编译前要指定预编译的平台、架构、指令集等参数。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nnvm.compiler</span>
<span class="kn">import</span> <span class="nn">nnvm.testing</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="kn">import</span> <span class="n">graph_runtime</span>
<span class="kn">import</span> <span class="nn">mxnet</span> <span class="kn">as</span> <span class="nn">mx</span>
<span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">ndarray</span> <span class="k">as</span> <span class="n">nd</span>

<span class="n">prefix</span><span class="p">,</span><span class="n">epoch</span> <span class="o">=</span> <span class="sa"></span><span class="s2">&#34;</span><span class="s2">emore1</span><span class="s2">&#34;</span><span class="p">,</span><span class="mi">0</span>
<span class="n">sym</span><span class="p">,</span> <span class="n">arg_params</span><span class="p">,</span> <span class="n">aux_params</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
<span class="n">image_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">112</span><span class="p">,</span> <span class="mi">112</span><span class="p">)</span>
<span class="n">opt_level</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">shape_dict</span> <span class="o">=</span> <span class="p">{</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">data</span><span class="s1">&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">*</span><span class="n">image_size</span><span class="p">)</span><span class="p">}</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">llvm -mcpu=haswell</span><span class="s2">&#34;</span><span class="p">)</span>
<span class="c1"># &#34;target&#34; means your target platform you want to compile.</span>

<span class="c1">#target = tvm.target.create(&#34;llvm -mcpu=broadwell&#34;)</span>
<span class="n">nnvm_sym</span><span class="p">,</span> <span class="n">nnvm_params</span> <span class="o">=</span> <span class="n">nnvm</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_mxnet</span><span class="p">(</span><span class="n">sym</span><span class="p">,</span> <span class="n">arg_params</span><span class="p">,</span> <span class="n">aux_params</span><span class="p">)</span>
<span class="k">with</span> <span class="n">nnvm</span><span class="o">.</span><span class="n">compiler</span><span class="o">.</span><span class="n">build_config</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="n">opt_level</span><span class="p">)</span><span class="p">:</span>
   <span class="n">graph</span><span class="p">,</span> <span class="n">lib</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">nnvm</span><span class="o">.</span><span class="n">compiler</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">nnvm_sym</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">shape_dict</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">nnvm_params</span><span class="p">)</span>
<span class="n">lib</span><span class="o">.</span><span class="n">export_library</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">./deploy_lib.so</span><span class="s2">&#34;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa"></span><span class="s1">&#39;</span><span class="s1">lib export succeefully</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">./deploy_graph.json</span><span class="s2">&#34;</span><span class="p">,</span> <span class="sa"></span><span class="s2">&#34;</span><span class="s2">w</span><span class="s2">&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fo</span><span class="p">:</span>
   <span class="n">fo</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">graph</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">./deploy_param.params</span><span class="s2">&#34;</span><span class="p">,</span> <span class="sa"></span><span class="s2">&#34;</span><span class="s2">wb</span><span class="s2">&#34;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fo</span><span class="p">:</span>
   <span class="n">fo</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">nnvm</span><span class="o">.</span><span class="n">compiler</span><span class="o">.</span><span class="n">save_param_dict</span><span class="p">(</span><span class="n">params</span><span class="p">)</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>运行该代码后会生成三个文件分别为deploy_lib.so 、deploy_graph.json 、deploy_param.params 。其中deploy_lib.so 为编译好的动态库，deploy_graph.json为部署使用的计算图、deploy_param.params为模型参数。</p>
<h4 id="使用tvm-python-runtime-进行简单的测试">使用TVM Python Runtime 进行简单的测试</h4>
<p>TVM的Runtime(运行时)并不需要任何依赖，直接clone tvm后 make runtime.即可。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nnvm.compiler</span>
<span class="kn">import</span> <span class="nn">nnvm.testing</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="kn">import</span> <span class="n">graph_runtime</span>
<span class="kn">import</span> <span class="nn">mxnet</span> <span class="kn">as</span> <span class="nn">mx</span>
<span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">ndarray</span> <span class="k">as</span> <span class="n">nd</span>

<span class="n">ctx</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">(</span><span class="p">)</span>
<span class="c1"># load the module back.</span>
<span class="n">loaded_json</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">./deploy_graph.json</span><span class="s2">&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="p">)</span>
<span class="n">loaded_lib</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">./deploy_lib.so</span><span class="s2">&#34;</span><span class="p">)</span>
<span class="n">loaded_params</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">./deploy_param.params</span><span class="s2">&#34;</span><span class="p">,</span> <span class="sa"></span><span class="s2">&#34;</span><span class="s2">rb</span><span class="s2">&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="p">)</span><span class="p">)</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">data_shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">float32</span><span class="s2">&#34;</span><span class="p">)</span><span class="p">)</span>

<span class="n">module</span> <span class="o">=</span> <span class="n">graph_runtime</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">loaded_json</span><span class="p">,</span> <span class="n">loaded_lib</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">module</span><span class="o">.</span><span class="n">load_params</span><span class="p">(</span><span class="n">loaded_params</span><span class="p">)</span>

<span class="c1"># Tiny benchmark test.</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="p">:</span>
   <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="p">)</span>
   <span class="n">module</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">input_data</span><span class="p">)</span>
   <span class="k">print</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">(</span><span class="p">)</span> <span class="o">-</span> <span class="n">t0</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h4 id="使用c来推理mobilefacenet人脸识别模型">使用C++来推理MobileFaceNet人脸识别模型</h4>
<p>在C++下 TVM Runtime（运行时）仅仅需要编译时输出的so文件，包含  “tvm_runtime_pack.cc” 。runtime的体积也比较小，只有几百K。</p>
<p>下列的CPP代码包含了通过输入一张对齐后的人脸识别照片，输出归一化的之后的人脸向量。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-cpp" data-lang="cpp"><span class="cp">#</span><span class="cp">include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span><span class="cp"></span><span class="cp">#</span><span class="cp">include</span> <span class="cpf">&lt;opencv2/opencv.hpp&gt;</span><span class="cp">
</span><span class="cp"></span><span class="cp">#</span><span class="cp">include</span> <span class="cpf">&lt;tvm/runtime/module.h&gt;</span><span class="cp">
</span><span class="cp"></span><span class="cp">#</span><span class="cp">include</span> <span class="cpf">&lt;tvm/runtime/registry.h&gt;</span><span class="cp">
</span><span class="cp"></span><span class="cp">#</span><span class="cp">include</span> <span class="cpf">&lt;tvm/runtime/packed_func.h&gt;</span><span class="cp">
</span><span class="cp"></span>
<span class="k">class</span> <span class="nc">FR_MFN_Deploy</span><span class="p">{</span>
    
    <span class="k">private</span><span class="o">:</span>
        <span class="kt">void</span> <span class="o">*</span> <span class="n">handle</span><span class="p">;</span>
    
    <span class="k">public</span><span class="o">:</span>
        <span class="n">FR_MFN_Deploy</span><span class="p">(</span><span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">string</span> <span class="n">modelFolder</span><span class="p">)</span>
        <span class="p">{</span>
    
            <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">Module</span> <span class="n">mod_syslib</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">Module</span><span class="o">:</span><span class="o">:</span><span class="n">LoadFromFile</span><span class="p">(</span><span class="n">modelFolder</span> <span class="o">+</span> <span class="sa"></span><span class="s">&#34;</span><span class="s">/deploy_lib.so</span><span class="s">&#34;</span><span class="p">)</span><span class="p">;</span>
            <span class="c1">//load graph
</span><span class="c1"></span>            <span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">ifstream</span> <span class="n">json_in</span><span class="p">(</span><span class="n">modelFolder</span> <span class="o">+</span> <span class="sa"></span><span class="s">&#34;</span><span class="s">/deploy_graph.json</span><span class="s">&#34;</span><span class="p">)</span><span class="p">;</span>
            <span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">string</span> <span class="n">json_data</span><span class="p">(</span><span class="p">(</span><span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">istreambuf_iterator</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span><span class="p">(</span><span class="n">json_in</span><span class="p">)</span><span class="p">)</span><span class="p">,</span> <span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">istreambuf_iterator</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">;</span>
            <span class="n">json_in</span><span class="p">.</span><span class="n">close</span><span class="p">(</span><span class="p">)</span><span class="p">;</span>
    
            <span class="kt">int</span> <span class="n">device_type</span> <span class="o">=</span> <span class="n">kDLCPU</span><span class="p">;</span>
            <span class="kt">int</span> <span class="n">device_id</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
            <span class="c1">// get global function module for graph runtime
</span><span class="c1"></span>            <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">Module</span> <span class="n">mod</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">Registry</span><span class="o">:</span><span class="o">:</span><span class="n">Get</span><span class="p">(</span><span class="sa"></span><span class="s">&#34;</span><span class="s">tvm.graph_runtime.create</span><span class="s">&#34;</span><span class="p">)</span><span class="p">)</span><span class="p">(</span><span class="n">json_data</span><span class="p">,</span> <span class="n">mod_syslib</span><span class="p">,</span> <span class="n">device_type</span><span class="p">,</span> <span class="n">device_id</span><span class="p">)</span><span class="p">;</span>
            <span class="k">this</span><span class="o">-</span><span class="o">&gt;</span><span class="n">handle</span> <span class="o">=</span> <span class="k">new</span> <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">Module</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span><span class="p">;</span>
    
            <span class="c1">//load param
</span><span class="c1"></span>            <span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">ifstream</span> <span class="n">params_in</span><span class="p">(</span><span class="n">modelFolder</span> <span class="o">+</span> <span class="sa"></span><span class="s">&#34;</span><span class="s">/deploy_param.params</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">ios</span><span class="o">:</span><span class="o">:</span><span class="n">binary</span><span class="p">)</span><span class="p">;</span>
            <span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">string</span> <span class="n">params_data</span><span class="p">(</span><span class="p">(</span><span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">istreambuf_iterator</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span><span class="p">(</span><span class="n">params_in</span><span class="p">)</span><span class="p">)</span><span class="p">,</span> <span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">istreambuf_iterator</span><span class="o">&lt;</span><span class="kt">char</span><span class="o">&gt;</span><span class="p">(</span><span class="p">)</span><span class="p">)</span><span class="p">;</span>
            <span class="n">params_in</span><span class="p">.</span><span class="n">close</span><span class="p">(</span><span class="p">)</span><span class="p">;</span>
    
            <span class="n">TVMByteArray</span> <span class="n">params_arr</span><span class="p">;</span>
            <span class="n">params_arr</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">params_data</span><span class="p">.</span><span class="n">c_str</span><span class="p">(</span><span class="p">)</span><span class="p">;</span>
            <span class="n">params_arr</span><span class="p">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">params_data</span><span class="p">.</span><span class="n">length</span><span class="p">(</span><span class="p">)</span><span class="p">;</span>
            <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">PackedFunc</span> <span class="n">load_params</span> <span class="o">=</span> <span class="n">mod</span><span class="p">.</span><span class="n">GetFunction</span><span class="p">(</span><span class="sa"></span><span class="s">&#34;</span><span class="s">load_params</span><span class="s">&#34;</span><span class="p">)</span><span class="p">;</span>
            <span class="n">load_params</span><span class="p">(</span><span class="n">params_arr</span><span class="p">)</span><span class="p">;</span>
        <span class="p">}</span>
    
        <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="n">forward</span><span class="p">(</span><span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="n">inputImageAligned</span><span class="p">)</span>
        <span class="p">{</span>
            <span class="c1">//mobilefacnet preprocess has been written in graph.
</span><span class="c1"></span>            <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="n">tensor</span> <span class="o">=</span> <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">dnn</span><span class="o">:</span><span class="o">:</span><span class="n">blobFromImage</span><span class="p">(</span><span class="n">inputImageAligned</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Size</span><span class="p">(</span><span class="mi">112</span><span class="p">,</span><span class="mi">112</span><span class="p">)</span><span class="p">,</span><span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Scalar</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="p">,</span><span class="nb">true</span><span class="p">)</span><span class="p">;</span>
            <span class="c1">//convert uint8 to float32 and convert to RGB via opencv dnn function
</span><span class="c1"></span>            <span class="n">DLTensor</span><span class="o">*</span> <span class="n">input</span><span class="p">;</span>
            <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">dtype_code</span> <span class="o">=</span> <span class="n">kDLFloat</span><span class="p">;</span>
            <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">dtype_bits</span> <span class="o">=</span> <span class="mi">32</span><span class="p">;</span>
            <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">dtype_lanes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
            <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">device_type</span> <span class="o">=</span> <span class="n">kDLCPU</span><span class="p">;</span>
            <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">device_id</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
            <span class="k">constexpr</span> <span class="kt">int</span> <span class="n">in_ndim</span> <span class="o">=</span> <span class="mi">4</span><span class="p">;</span>
            <span class="k">const</span> <span class="kt">int64_t</span> <span class="n">in_shape</span><span class="p">[</span><span class="n">in_ndim</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">112</span><span class="p">,</span> <span class="mi">112</span><span class="p">}</span><span class="p">;</span>
            <span class="n">TVMArrayAlloc</span><span class="p">(</span><span class="n">in_shape</span><span class="p">,</span> <span class="n">in_ndim</span><span class="p">,</span> <span class="n">dtype_code</span><span class="p">,</span> <span class="n">dtype_bits</span><span class="p">,</span> <span class="n">dtype_lanes</span><span class="p">,</span> <span class="n">device_type</span><span class="p">,</span> <span class="n">device_id</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">input</span><span class="p">)</span><span class="p">;</span><span class="c1">//
</span><span class="c1"></span>            <span class="n">TVMArrayCopyFromBytes</span><span class="p">(</span><span class="n">input</span><span class="p">,</span><span class="n">tensor</span><span class="p">.</span><span class="n">data</span><span class="p">,</span><span class="mi">112</span><span class="o">*</span><span class="mi">3</span><span class="o">*</span><span class="mi">112</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span><span class="p">;</span>
            <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">Module</span><span class="o">*</span> <span class="n">mod</span> <span class="o">=</span> <span class="p">(</span><span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">Module</span><span class="o">*</span><span class="p">)</span><span class="n">handle</span><span class="p">;</span>
            <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">PackedFunc</span> <span class="n">set_input</span> <span class="o">=</span> <span class="n">mod</span><span class="o">-</span><span class="o">&gt;</span><span class="n">GetFunction</span><span class="p">(</span><span class="sa"></span><span class="s">&#34;</span><span class="s">set_input</span><span class="s">&#34;</span><span class="p">)</span><span class="p">;</span>
            <span class="n">set_input</span><span class="p">(</span><span class="sa"></span><span class="s">&#34;</span><span class="s">data</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">input</span><span class="p">)</span><span class="p">;</span>
            <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">PackedFunc</span> <span class="n">run</span> <span class="o">=</span> <span class="n">mod</span><span class="o">-</span><span class="o">&gt;</span><span class="n">GetFunction</span><span class="p">(</span><span class="sa"></span><span class="s">&#34;</span><span class="s">run</span><span class="s">&#34;</span><span class="p">)</span><span class="p">;</span>
            <span class="n">run</span><span class="p">(</span><span class="p">)</span><span class="p">;</span>
            <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">PackedFunc</span> <span class="n">get_output</span> <span class="o">=</span> <span class="n">mod</span><span class="o">-</span><span class="o">&gt;</span><span class="n">GetFunction</span><span class="p">(</span><span class="sa"></span><span class="s">&#34;</span><span class="s">get_output</span><span class="s">&#34;</span><span class="p">)</span><span class="p">;</span>
            <span class="n">tvm</span><span class="o">:</span><span class="o">:</span><span class="n">runtime</span><span class="o">:</span><span class="o">:</span><span class="n">NDArray</span> <span class="n">res</span> <span class="o">=</span> <span class="n">get_output</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="p">;</span>
            <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="n">vector</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">CV_32F</span><span class="p">)</span><span class="p">;</span>
            <span class="n">memcpy</span><span class="p">(</span><span class="n">vector</span><span class="p">.</span><span class="n">data</span><span class="p">,</span><span class="n">res</span><span class="o">-</span><span class="o">&gt;</span><span class="n">data</span><span class="p">,</span><span class="mi">128</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span><span class="p">;</span>
            <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="n">_l2</span><span class="p">;</span>
            <span class="c1">// normlize 
</span><span class="c1"></span>            <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">multiply</span><span class="p">(</span><span class="n">vector</span><span class="p">,</span><span class="n">vector</span><span class="p">,</span><span class="n">_l2</span><span class="p">)</span><span class="p">;</span>
            <span class="kt">float</span> <span class="n">l2</span> <span class="o">=</span>  <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">sqrt</span><span class="p">(</span><span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">sum</span><span class="p">(</span><span class="n">_l2</span><span class="p">)</span><span class="p">.</span><span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="p">)</span><span class="p">;</span>
            <span class="n">vector</span> <span class="o">=</span> <span class="n">vector</span> <span class="o">/</span> <span class="n">l2</span><span class="p">;</span>
            <span class="n">TVMArrayFree</span><span class="p">(</span><span class="n">input</span><span class="p">)</span><span class="p">;</span>
            <span class="k">return</span> <span class="n">vector</span><span class="p">;</span>
    <span class="p">}</span>

<span class="p">}</span><span class="p">;</span>
</code></pre></td></tr></table>
</div>
</div><p>我们可以通过输入两张对齐后的人脸照片来提取人脸向量。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-cpp" data-lang="cpp"><span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="n">A</span> <span class="o">=</span> <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">imread</span><span class="p">(</span><span class="sa"></span><span class="s">&#34;</span><span class="s">/Users/yujinke/Desktop/align_id/aligned/20171231115821836_face.jpg</span><span class="s">&#34;</span><span class="p">)</span><span class="p">;</span>
<span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="n">B</span> <span class="o">=</span> <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">imread</span><span class="p">(</span><span class="sa"></span><span class="s">&#34;</span><span class="s">/Users/yujinke/Desktop/align_id/aligned/20171231115821836_idcard.jpg</span><span class="s">&#34;</span><span class="p">)</span><span class="p">;</span>
<span class="n">FR_MFN_Deploy</span> <span class="nf">deploy</span><span class="p">(</span><span class="sa"></span><span class="s">&#34;</span><span class="s">./models</span><span class="s">&#34;</span><span class="p">)</span><span class="p">;</span>
<span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="n">v2</span> <span class="o">=</span> <span class="n">deploy</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">B</span><span class="p">)</span><span class="p">;</span>
<span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="n">v1</span> <span class="o">=</span> <span class="n">deploy</span><span class="p">.</span><span class="n">forward</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="p">;</span>
</code></pre></td></tr></table>
</div>
</div><p>测量余弦相似度</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-cpp" data-lang="cpp"><span class="kr">inline</span> <span class="kt">float</span> <span class="nf">CosineDistance</span><span class="p">(</span><span class="k">const</span> <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">v1</span><span class="p">,</span><span class="k">const</span> <span class="n">cv</span><span class="o">:</span><span class="o">:</span><span class="n">Mat</span> <span class="o">&amp;</span><span class="n">v2</span><span class="p">)</span><span class="p">{</span>
    <span class="k">return</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">v1</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v2</span><span class="p">)</span><span class="p">)</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">cout</span><span class="o">&lt;</span><span class="o">&lt;</span><span class="n">CosineDistance</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span><span class="n">v2</span><span class="p">)</span><span class="o">&lt;</span><span class="o">&lt;</span><span class="n">std</span><span class="o">:</span><span class="o">:</span><span class="n">endl</span><span class="p">;</span>
</code></pre></td></tr></table>
</div>
</div><p>简单的配置一个cmake文件</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-bash" data-lang="bash">cmake_minimum_required<span class="o">(</span>VERSION 3.6<span class="o">)</span>
project<span class="o">(</span>tvm_mobilefacenet<span class="o">)</span>
set<span class="o">(</span>CMAKE_CXX_FLAGS <span class="s2">&#34;</span><span class="si">${</span><span class="nv">CMAKE_CXX_FLAGS</span><span class="si">}</span><span class="s2"> -std=c++11 -ldl -lpthread</span><span class="s2">&#34;</span><span class="o">)</span>
SET<span class="o">(</span>CMAKE_RUNTIME_OUTPUT_DIRECTORY <span class="si">${</span><span class="nv">CMAKE_CURRENT_SOURCE_DIR</span><span class="si">}</span><span class="o">)</span>
SET<span class="o">(</span>CMAKE_LIBRARY_OUTPUT_DIRECTORY  <span class="si">${</span><span class="nv">CMAKE_CURRENT_SOURCE_DIR</span><span class="si">}</span><span class="o">)</span>
SET<span class="o">(</span>HOME_TVM /Users/jackyu/downloads/tvm-0.5<span class="o">)</span>
find_package<span class="o">(</span>OPENCV REQUIRED<span class="o">)</span>

INCLUDE_DIRECTORIES<span class="o">(</span><span class="si">${</span><span class="nv">OpenCV_INCLUDE_DIRS</span><span class="si">}</span><span class="o">)</span>
INCLUDE_DIRECTORIES<span class="o">(</span><span class="si">${</span><span class="nv">HOME_TVM</span><span class="si">}</span>/include<span class="o">)</span>
INCLUDE_DIRECTORIES<span class="o">(</span><span class="si">${</span><span class="nv">HOME_TVM</span><span class="si">}</span>/3rdparty/dmlc-core/include<span class="o">)</span>
INCLUDE_DIRECTORIES<span class="o">(</span><span class="si">${</span><span class="nv">HOME_TVM</span><span class="si">}</span>/3rdparty/dlpack/include<span class="o">)</span>

add_executable<span class="o">(</span>tvm_mobilefacenet  tvm_runtime_pack.cc main.cpp<span class="o">)</span>
target_link_libraries<span class="o">(</span>tvm_mobilefacenet    <span class="si">${</span><span class="nv">OpenCV_LIBS</span><span class="si">}</span><span class="o">)</span>
</code></pre></td></tr></table>
</div>
</div><h4 id="todo如何在在android下部署整套人脸识别流程">Todo：如何在在Android下部署整套人脸识别流程</h4>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">lflxp</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        0001-01-01
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      
      <nav class="post-nav">
        <a class="prev" href="/post/hyperdl-tutorial/5.%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2/readme/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default"></span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/hyperdl-tutorial/6.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%BE%E8%AE%A1/mtcnn-%E4%BC%98%E5%8C%96/">
            <span class="next-text nav-default"></span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="comments-gitment"></div>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/default.min.css" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/gitment.browser.min.js" crossorigin="anonymous"></script>
    <script type="text/javascript">
      var gitment = new Gitment({
        id: '0001-01-01 00:00:00 \x2b0000 UTC',
        title: '',
        link: decodeURI(location.href),
        desc: '在CPP下使用TVM来部署mxnet模型（以Insightface为例） 自从AI被炒作以来，各个深度学习框架层出不穷。我们通常来讲，作为AI从业者，我们通常经历着标注-训练-部署的过程。其中部署是较为痛苦的工作，尤其是在跨平台如（移动端需要native对接的时候。）当然用于inference框架同样也是层出不穷。但是大多数框架框架往往性能都一般，或者缺少相关op，或者就是转换模型较为困难。TVM的出现很大程度上为模型部署带来了福音。\n但是网上将用于TVM部署的教程还比较少，尤其是通过cpp和移动端部署。本文以Insightface Model Zoo中的MobileFaceNet为例，介绍一下如何编译Mxnet模型、在python下inference、在cpp下inference、对比人脸余弦距离、以及在android下的部署。\n安装 TVM编译环境的安装需要LLVM编译器，可以简要遵循官方的教程。 official installation tutorial.\nLLVM 7.0 可能会导致编译错误，推荐使用LLVM 6.0.1\n编译模型 TVM使用了一系列的优化措施来优化计算图，当模型编译完之后会生成若干个编译好的文件。在编译前要指定预编译的平台、架构、指令集等参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  import numpy as np import nnvm.compiler import nnvm.testing import tvm from tvm.contrib import graph_runtime import mxnet as mx from mxnet import ndarray as nd prefix,epoch = \x26#34;emore1\x26#34;,0 sym, arg_params, aux_params = mx.',
        owner: 'lflxp',
        repo: 'https:\/\/github.com\/lflxp\/lflxp.github.com',
        oauth: {
          client_id: '',
          client_secret: ''
        }
      });
      gitment.render('comments-gitment');
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/imsun/gitment">comments powered by gitment.</a></noscript>

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:382023823@qq.com" class="iconfont icon-email" title="email"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-twitter" title="twitter"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-facebook" title="facebook"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-google" title="google"></a>
      <a href="https://github.com/lflxp" class="iconfont icon-github" title="github"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-weibo" title="weibo"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-douban" title="douban"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-pocket" title="pocket"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-instagram" title="instagram"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-gitlab" title="gitlab"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="https://www.lflxp.cn/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2016 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">lflxp.cn 版权所有 ICP证：<a href='http://www.beian.miit.gov.cn' target='_blank'>渝ICP备17011066号-1</a></span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.min.js" integrity="sha256-jwCP0NAdCBloaIWTWHmW4i3snUNMHUNO+jr9rYd2iOI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.locales.min.js" integrity="sha256-ZwofwC1Lf/faQCzN7nZtfijVV6hSwxjQMwXL4gn9qU8=" crossorigin="anonymous"></script>
  <script><!-- NOTE: timeago.js uses the language code format like "zh_CN" (underscore and case sensitive) -->
    var languageCode = "zh-cn".replace(/-/g, '_').replace(/_(.*)/, function ($0, $1) {return $0.replace($1, $1.toUpperCase());});
    timeago().render(document.querySelectorAll('.timeago'), languageCode);
    timeago.cancel();  
  </script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', '渝ICP备17011066号-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
