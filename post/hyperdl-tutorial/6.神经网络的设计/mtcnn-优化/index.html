<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title> - 爱像水墨青花</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="lflxp" /><meta name="description" content="MTCNN优化和另类用法 MTCNN是目前应用十分广泛的基于级联的特定目标检测器，也是少数能在传统硬件上落地的检测器，当然其优势不光光仅仅用于人脸检测这个任务。在人脸这个任务上，在少数人脸&amp;lt;5个人脸的情况下。其效能是第一梯队的水准。而且有着极大的优化空间（加上一些trick可以轻易的优化到极快的速度移动端 minSize60 60fps 1080p mt.）。而且其Alignment的准确率和精度也相对相对比较高，在工业界的人脸识别工作中，往往都采用MTCNN的点位来进行对齐。
人脸跟踪是一项很重要的任务，cascade based检测模型，在人脸基数增大的同时，往往速度上容易爆炸，在工程应用中往往需要极致的速度。在有些效率比较低的ARM板子上，一些correlation filter tracker都不能取得很好的时效性。
MTCNN的多任务特性为我们权衡这个问题提供的特别巧妙的方法。
MTCNN的优化 MTCNN (Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks)是Kaipeng Zhang在2016年提出的Face Detector,也是基于Cascade CNN来改进的Face Detector。文章认为人脸检测任务中的 face bounding box regression 和 landmark 任务存在潜在关系，可以提高人脸检测效果。由于其多任务和全卷积的特性其速度要比Cascade CNN要快不少。由于MTCNN训练的Pipeline比较繁琐，需要一定的经验和调试，后继有人又提出了把Cascade pipeline联合起来训练的(Facecraft 和 xxx 两篇文章 都来自于商汤)。后来还有加Anchor 的做法 如 Anchor CNN 本文不再赘述。本文主要是从工程角度在FDDB下降不是特别多的情况下来改进和为了人脸识别而检测人脸的目的来加速MTCNN。
基本原理 MTCNN基本原理是使用全卷积的P-Net在多尺度的待检图像上生成候选框，接着通过R-Net和O-Net来过滤。
MTCNN的结构 我们可以看到其网络结构和Cascade CNN基本是一致的。由于文章的发表时间是2016年。一些较为modern的网络设计trick在当时也没有被提出。所以我们改进的空间还是有的。我们做了一些实验，也发现了MTCNN速度的瓶颈在哪。
主要是以下几点
 图片越大Pnet耗时也就越大。 人脸越多Onet和Rnet耗时越大。 噪点比较多的夜晚图像会导致Pnet误检测增多。  针对第一和第二个问题，我们选择优化网络结构，使之精度下降不太多的情况下，尽可能的减少计算量，第一个我们想到的是Mobilenet系列中的Depthwise卷积。
Depthwise卷积 Depthwise卷积最初来源于Xception。其思路比较直接，先是对输入图的每个通道进行卷积，然后再由1x1卷积将他们合并起来，大量实验证明的这个操作基本可以等同于普通的Sptial卷积。并且在IO效率和性能不变的情况下，计算量降低9倍。我们可以利用这个思路替换Pnet和Rnet和Onet中的卷积操作使之速度有着大幅度提升。
但是有时候即使加了Depthwise卷积在某些嵌入式环境下，效果仍然不是很好，达不到良好的效果。我们发现Depthwise卷积80-90%的计算量基本都被后面的1x1卷积占据了。这时我们想是否也可以把1x1卷积也用类似于Depthwise的分组卷积来替代，但是一旦把后面1x1卷积分组，组与组之间的信息就无法相互交流了，于是shuffle-channel的出现很好的解决了这个问题。
shuffle-channel shuffle-channel来源于旷世的ShuffleNet。虽然这篇文章宣称的精度难以复现。但其shuffle-channel的思想是非常值得借鉴的。shuffle-channel的原理将特征的通道平均分到不同组里面。是之每个组卷积的时候能得到其他组的信息。起到了一个组之间通信的作用。
我们做了一些实验来证明了本文论述的结果
    sets-1 sets-2     MTCNN 21fps 11fps   MTCNN-dw 131fps 101fps   MTCNN-shuffle 220fps 135fps    其中 sets-1 数据集均为一张人脸，sets-2数据集为2-4张人脸的普通监控场景。测试框架是caffe。环境为Macbook 2015 r15 2." /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.62.2 with theme even" />


<link rel="canonical" href="https://www.lflxp.cn/post/hyperdl-tutorial/6.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%BE%E8%AE%A1/mtcnn-%E4%BC%98%E5%8C%96/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="" />
<meta property="og:description" content="MTCNN优化和另类用法 MTCNN是目前应用十分广泛的基于级联的特定目标检测器，也是少数能在传统硬件上落地的检测器，当然其优势不光光仅仅用于人脸检测这个任务。在人脸这个任务上，在少数人脸&lt;5个人脸的情况下。其效能是第一梯队的水准。而且有着极大的优化空间（加上一些trick可以轻易的优化到极快的速度移动端 minSize60 60fps 1080p mt.）。而且其Alignment的准确率和精度也相对相对比较高，在工业界的人脸识别工作中，往往都采用MTCNN的点位来进行对齐。
人脸跟踪是一项很重要的任务，cascade based检测模型，在人脸基数增大的同时，往往速度上容易爆炸，在工程应用中往往需要极致的速度。在有些效率比较低的ARM板子上，一些correlation filter tracker都不能取得很好的时效性。
MTCNN的多任务特性为我们权衡这个问题提供的特别巧妙的方法。
MTCNN的优化 MTCNN (Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks)是Kaipeng Zhang在2016年提出的Face Detector,也是基于Cascade CNN来改进的Face Detector。文章认为人脸检测任务中的 face bounding box regression 和 landmark 任务存在潜在关系，可以提高人脸检测效果。由于其多任务和全卷积的特性其速度要比Cascade CNN要快不少。由于MTCNN训练的Pipeline比较繁琐，需要一定的经验和调试，后继有人又提出了把Cascade pipeline联合起来训练的(Facecraft 和 xxx 两篇文章 都来自于商汤)。后来还有加Anchor 的做法 如 Anchor CNN 本文不再赘述。本文主要是从工程角度在FDDB下降不是特别多的情况下来改进和为了人脸识别而检测人脸的目的来加速MTCNN。
基本原理 MTCNN基本原理是使用全卷积的P-Net在多尺度的待检图像上生成候选框，接着通过R-Net和O-Net来过滤。
MTCNN的结构 我们可以看到其网络结构和Cascade CNN基本是一致的。由于文章的发表时间是2016年。一些较为modern的网络设计trick在当时也没有被提出。所以我们改进的空间还是有的。我们做了一些实验，也发现了MTCNN速度的瓶颈在哪。
主要是以下几点
 图片越大Pnet耗时也就越大。 人脸越多Onet和Rnet耗时越大。 噪点比较多的夜晚图像会导致Pnet误检测增多。  针对第一和第二个问题，我们选择优化网络结构，使之精度下降不太多的情况下，尽可能的减少计算量，第一个我们想到的是Mobilenet系列中的Depthwise卷积。
Depthwise卷积 Depthwise卷积最初来源于Xception。其思路比较直接，先是对输入图的每个通道进行卷积，然后再由1x1卷积将他们合并起来，大量实验证明的这个操作基本可以等同于普通的Sptial卷积。并且在IO效率和性能不变的情况下，计算量降低9倍。我们可以利用这个思路替换Pnet和Rnet和Onet中的卷积操作使之速度有着大幅度提升。
但是有时候即使加了Depthwise卷积在某些嵌入式环境下，效果仍然不是很好，达不到良好的效果。我们发现Depthwise卷积80-90%的计算量基本都被后面的1x1卷积占据了。这时我们想是否也可以把1x1卷积也用类似于Depthwise的分组卷积来替代，但是一旦把后面1x1卷积分组，组与组之间的信息就无法相互交流了，于是shuffle-channel的出现很好的解决了这个问题。
shuffle-channel shuffle-channel来源于旷世的ShuffleNet。虽然这篇文章宣称的精度难以复现。但其shuffle-channel的思想是非常值得借鉴的。shuffle-channel的原理将特征的通道平均分到不同组里面。是之每个组卷积的时候能得到其他组的信息。起到了一个组之间通信的作用。
我们做了一些实验来证明了本文论述的结果
    sets-1 sets-2     MTCNN 21fps 11fps   MTCNN-dw 131fps 101fps   MTCNN-shuffle 220fps 135fps    其中 sets-1 数据集均为一张人脸，sets-2数据集为2-4张人脸的普通监控场景。测试框架是caffe。环境为Macbook 2015 r15 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.lflxp.cn/post/hyperdl-tutorial/6.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%BE%E8%AE%A1/mtcnn-%E4%BC%98%E5%8C%96/" />

<meta itemprop="name" content="">
<meta itemprop="description" content="MTCNN优化和另类用法 MTCNN是目前应用十分广泛的基于级联的特定目标检测器，也是少数能在传统硬件上落地的检测器，当然其优势不光光仅仅用于人脸检测这个任务。在人脸这个任务上，在少数人脸&lt;5个人脸的情况下。其效能是第一梯队的水准。而且有着极大的优化空间（加上一些trick可以轻易的优化到极快的速度移动端 minSize60 60fps 1080p mt.）。而且其Alignment的准确率和精度也相对相对比较高，在工业界的人脸识别工作中，往往都采用MTCNN的点位来进行对齐。
人脸跟踪是一项很重要的任务，cascade based检测模型，在人脸基数增大的同时，往往速度上容易爆炸，在工程应用中往往需要极致的速度。在有些效率比较低的ARM板子上，一些correlation filter tracker都不能取得很好的时效性。
MTCNN的多任务特性为我们权衡这个问题提供的特别巧妙的方法。
MTCNN的优化 MTCNN (Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks)是Kaipeng Zhang在2016年提出的Face Detector,也是基于Cascade CNN来改进的Face Detector。文章认为人脸检测任务中的 face bounding box regression 和 landmark 任务存在潜在关系，可以提高人脸检测效果。由于其多任务和全卷积的特性其速度要比Cascade CNN要快不少。由于MTCNN训练的Pipeline比较繁琐，需要一定的经验和调试，后继有人又提出了把Cascade pipeline联合起来训练的(Facecraft 和 xxx 两篇文章 都来自于商汤)。后来还有加Anchor 的做法 如 Anchor CNN 本文不再赘述。本文主要是从工程角度在FDDB下降不是特别多的情况下来改进和为了人脸识别而检测人脸的目的来加速MTCNN。
基本原理 MTCNN基本原理是使用全卷积的P-Net在多尺度的待检图像上生成候选框，接着通过R-Net和O-Net来过滤。
MTCNN的结构 我们可以看到其网络结构和Cascade CNN基本是一致的。由于文章的发表时间是2016年。一些较为modern的网络设计trick在当时也没有被提出。所以我们改进的空间还是有的。我们做了一些实验，也发现了MTCNN速度的瓶颈在哪。
主要是以下几点
 图片越大Pnet耗时也就越大。 人脸越多Onet和Rnet耗时越大。 噪点比较多的夜晚图像会导致Pnet误检测增多。  针对第一和第二个问题，我们选择优化网络结构，使之精度下降不太多的情况下，尽可能的减少计算量，第一个我们想到的是Mobilenet系列中的Depthwise卷积。
Depthwise卷积 Depthwise卷积最初来源于Xception。其思路比较直接，先是对输入图的每个通道进行卷积，然后再由1x1卷积将他们合并起来，大量实验证明的这个操作基本可以等同于普通的Sptial卷积。并且在IO效率和性能不变的情况下，计算量降低9倍。我们可以利用这个思路替换Pnet和Rnet和Onet中的卷积操作使之速度有着大幅度提升。
但是有时候即使加了Depthwise卷积在某些嵌入式环境下，效果仍然不是很好，达不到良好的效果。我们发现Depthwise卷积80-90%的计算量基本都被后面的1x1卷积占据了。这时我们想是否也可以把1x1卷积也用类似于Depthwise的分组卷积来替代，但是一旦把后面1x1卷积分组，组与组之间的信息就无法相互交流了，于是shuffle-channel的出现很好的解决了这个问题。
shuffle-channel shuffle-channel来源于旷世的ShuffleNet。虽然这篇文章宣称的精度难以复现。但其shuffle-channel的思想是非常值得借鉴的。shuffle-channel的原理将特征的通道平均分到不同组里面。是之每个组卷积的时候能得到其他组的信息。起到了一个组之间通信的作用。
我们做了一些实验来证明了本文论述的结果
    sets-1 sets-2     MTCNN 21fps 11fps   MTCNN-dw 131fps 101fps   MTCNN-shuffle 220fps 135fps    其中 sets-1 数据集均为一张人脸，sets-2数据集为2-4张人脸的普通监控场景。测试框架是caffe。环境为Macbook 2015 r15 2.">

<meta itemprop="wordCount" content="89">



<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="MTCNN优化和另类用法 MTCNN是目前应用十分广泛的基于级联的特定目标检测器，也是少数能在传统硬件上落地的检测器，当然其优势不光光仅仅用于人脸检测这个任务。在人脸这个任务上，在少数人脸&lt;5个人脸的情况下。其效能是第一梯队的水准。而且有着极大的优化空间（加上一些trick可以轻易的优化到极快的速度移动端 minSize60 60fps 1080p mt.）。而且其Alignment的准确率和精度也相对相对比较高，在工业界的人脸识别工作中，往往都采用MTCNN的点位来进行对齐。
人脸跟踪是一项很重要的任务，cascade based检测模型，在人脸基数增大的同时，往往速度上容易爆炸，在工程应用中往往需要极致的速度。在有些效率比较低的ARM板子上，一些correlation filter tracker都不能取得很好的时效性。
MTCNN的多任务特性为我们权衡这个问题提供的特别巧妙的方法。
MTCNN的优化 MTCNN (Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks)是Kaipeng Zhang在2016年提出的Face Detector,也是基于Cascade CNN来改进的Face Detector。文章认为人脸检测任务中的 face bounding box regression 和 landmark 任务存在潜在关系，可以提高人脸检测效果。由于其多任务和全卷积的特性其速度要比Cascade CNN要快不少。由于MTCNN训练的Pipeline比较繁琐，需要一定的经验和调试，后继有人又提出了把Cascade pipeline联合起来训练的(Facecraft 和 xxx 两篇文章 都来自于商汤)。后来还有加Anchor 的做法 如 Anchor CNN 本文不再赘述。本文主要是从工程角度在FDDB下降不是特别多的情况下来改进和为了人脸识别而检测人脸的目的来加速MTCNN。
基本原理 MTCNN基本原理是使用全卷积的P-Net在多尺度的待检图像上生成候选框，接着通过R-Net和O-Net来过滤。
MTCNN的结构 我们可以看到其网络结构和Cascade CNN基本是一致的。由于文章的发表时间是2016年。一些较为modern的网络设计trick在当时也没有被提出。所以我们改进的空间还是有的。我们做了一些实验，也发现了MTCNN速度的瓶颈在哪。
主要是以下几点
 图片越大Pnet耗时也就越大。 人脸越多Onet和Rnet耗时越大。 噪点比较多的夜晚图像会导致Pnet误检测增多。  针对第一和第二个问题，我们选择优化网络结构，使之精度下降不太多的情况下，尽可能的减少计算量，第一个我们想到的是Mobilenet系列中的Depthwise卷积。
Depthwise卷积 Depthwise卷积最初来源于Xception。其思路比较直接，先是对输入图的每个通道进行卷积，然后再由1x1卷积将他们合并起来，大量实验证明的这个操作基本可以等同于普通的Sptial卷积。并且在IO效率和性能不变的情况下，计算量降低9倍。我们可以利用这个思路替换Pnet和Rnet和Onet中的卷积操作使之速度有着大幅度提升。
但是有时候即使加了Depthwise卷积在某些嵌入式环境下，效果仍然不是很好，达不到良好的效果。我们发现Depthwise卷积80-90%的计算量基本都被后面的1x1卷积占据了。这时我们想是否也可以把1x1卷积也用类似于Depthwise的分组卷积来替代，但是一旦把后面1x1卷积分组，组与组之间的信息就无法相互交流了，于是shuffle-channel的出现很好的解决了这个问题。
shuffle-channel shuffle-channel来源于旷世的ShuffleNet。虽然这篇文章宣称的精度难以复现。但其shuffle-channel的思想是非常值得借鉴的。shuffle-channel的原理将特征的通道平均分到不同组里面。是之每个组卷积的时候能得到其他组的信息。起到了一个组之间通信的作用。
我们做了一些实验来证明了本文论述的结果
    sets-1 sets-2     MTCNN 21fps 11fps   MTCNN-dw 131fps 101fps   MTCNN-shuffle 220fps 135fps    其中 sets-1 数据集均为一张人脸，sets-2数据集为2-4张人脸的普通监控场景。测试框架是caffe。环境为Macbook 2015 r15 2."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">琵琶</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">主页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">目录</li>
      </a><a href="/post/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">琵琶</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">主页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">目录</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title"></h1>

      <div class="post-meta">
        <span class="post-time"> 0001-01-01 </span>
        
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次阅读 </span>
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#mtcnn的优化">MTCNN的优化</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
  <div class="post-outdated">
    <div class="warn">
      <p>【注意】最后更新于 <span class="timeago" datetime="0001-01-01T00:00:00" title="January 1, 0001">January 1, 0001</span>，文中内容可能已过时，请谨慎使用。</p>
    </div>
  </div>
    <div class="post-content">
      <h1 id="mtcnn优化和另类用法">MTCNN优化和另类用法</h1>
<p>MTCNN是目前应用十分广泛的基于级联的特定目标检测器，也是少数能在传统硬件上落地的检测器，当然其优势不光光仅仅用于人脸检测这个任务。在人脸这个任务上，在少数人脸&lt;5个人脸的情况下。其效能是第一梯队的水准。而且有着极大的优化空间（加上一些trick可以轻易的优化到极快的速度移动端 minSize60  60fps  1080p mt.）。而且其Alignment的准确率和精度也相对相对比较高，在工业界的人脸识别工作中，往往都采用MTCNN的点位来进行对齐。</p>
<p>人脸跟踪是一项很重要的任务，cascade based检测模型，在人脸基数增大的同时，往往速度上容易爆炸，在工程应用中往往需要极致的速度。在有些效率比较低的ARM板子上，一些correlation filter tracker都不能取得很好的时效性。</p>
<p>MTCNN的多任务特性为我们权衡这个问题提供的特别巧妙的方法。</p>
<h3 id="mtcnn的优化">MTCNN的优化</h3>
<p>MTCNN (Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks)是Kaipeng Zhang在2016年提出的Face Detector,也是基于Cascade CNN来改进的Face Detector。文章认为人脸检测任务中的 face bounding box regression 和 landmark 任务存在潜在关系，可以提高人脸检测效果。由于其多任务和全卷积的特性其速度要比Cascade CNN要快不少。由于MTCNN训练的Pipeline比较繁琐，需要一定的经验和调试，后继有人又提出了把Cascade pipeline联合起来训练的(Facecraft 和 xxx 两篇文章 都来自于商汤)。后来还有加Anchor 的做法 如 Anchor CNN 本文不再赘述。本文主要是从工程角度在FDDB下降不是特别多的情况下来改进和为了人脸识别而检测人脸的目的来加速MTCNN。</p>
<h4 id="基本原理">基本原理</h4>
<p>MTCNN基本原理是使用全卷积的P-Net在多尺度的待检图像上生成候选框，接着通过R-Net和O-Net来过滤。</p>
<h4 id="mtcnn的结构">MTCNN的结构</h4>
<p><img src="./1.png" alt="20180630104620968"></p>
<p>我们可以看到其网络结构和Cascade CNN基本是一致的。由于文章的发表时间是2016年。一些较为modern的网络设计trick在当时也没有被提出。所以我们改进的空间还是有的。我们做了一些实验，也发现了MTCNN速度的瓶颈在哪。</p>
<p>主要是以下几点</p>
<ul>
<li>图片越大Pnet耗时也就越大。</li>
<li>人脸越多Onet和Rnet耗时越大。</li>
<li>噪点比较多的夜晚图像会导致Pnet误检测增多。</li>
</ul>
<p>针对第一和第二个问题，我们选择优化网络结构，使之精度下降不太多的情况下，尽可能的减少计算量，第一个我们想到的是Mobilenet系列中的Depthwise卷积。</p>
<h5 id="depthwise卷积">Depthwise卷积</h5>
<p><img src="./2.jpg" alt="6014825-cd2480acc62515a0"></p>
<p>Depthwise卷积最初来源于Xception。其思路比较直接，先是对输入图的每个通道进行卷积，然后再由1x1卷积将他们合并起来，大量实验证明的这个操作基本可以等同于普通的Sptial卷积。并且在IO效率和性能不变的情况下，计算量降低9倍。我们可以利用这个思路替换Pnet和Rnet和Onet中的卷积操作使之速度有着大幅度提升。</p>
<p>但是有时候即使加了Depthwise卷积在某些嵌入式环境下，效果仍然不是很好，达不到良好的效果。我们发现Depthwise卷积80-90%的计算量基本都被后面的1x1卷积占据了。这时我们想是否也可以把1x1卷积也用类似于Depthwise的分组卷积来替代，但是一旦把后面1x1卷积分组，组与组之间的信息就无法相互交流了，于是shuffle-channel的出现很好的解决了这个问题。</p>
<h5 id="shuffle-channel">shuffle-channel</h5>
<p><img src="./3.jpg" alt="6014825-59f0c95736fa2d9f"></p>
<p>shuffle-channel来源于旷世的ShuffleNet。虽然这篇文章宣称的精度难以复现。但其shuffle-channel的思想是非常值得借鉴的。shuffle-channel的原理将特征的通道平均分到不同组里面。是之每个组卷积的时候能得到其他组的信息。起到了一个组之间通信的作用。</p>
<p>我们做了一些实验来证明了本文论述的结果</p>
<table>
<thead>
<tr>
<th></th>
<th>sets-1</th>
<th>sets-2</th>
</tr>
</thead>
<tbody>
<tr>
<td>MTCNN</td>
<td>21fps</td>
<td>11fps</td>
</tr>
<tr>
<td>MTCNN-dw</td>
<td>131fps</td>
<td>101fps</td>
</tr>
<tr>
<td>MTCNN-shuffle</td>
<td>220fps</td>
<td>135fps</td>
</tr>
</tbody>
</table>
<p>其中 sets-1 数据集均为一张人脸，sets-2数据集为2-4张人脸的普通监控场景。测试框架是caffe。环境为Macbook 2015 r15 2.2GHZ 的结果。</p>
<h5 id="在pnet检测前使用中值滤波">在Pnet检测前使用中值滤波</h5>
<p>我们注意到在某些监控场景的夜晚图片，会有大量噪点的出现，我们知道由于CNN的不稳定性，所以导致了Pnet产生了大量的误检选区，为了减少这些噪点的出现，我们可以在Pnet检测之前，使用一次中值滤波来做个快速的去噪，总体实验下来有着不错的效果，每次inference时间也会更加的稳定。</p>
<h5 id="框架的加速">框架的加速</h5>
<p>我们将caffe版本的MTCNN inference改成opencv dnn，在普通的opencv dnn backend下取得了差不多近四倍的加速。</p>
<h5 id="mtcnn的并行">MTCNN的并行</h5>
<p>大家都知道Cascade架构都难以并行，使得在某些检测任务上，在GPU上的提升并不大，我们的做法是类似于FaceCraft的来将MTCNN的pipeline写进计算图，并且使用TVM来优化整个计算图。</p>
<h5 id="heading"></h5>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">lflxp</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        0001-01-01
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      
      <nav class="post-nav">
        <a class="prev" href="/post/hyperdl-tutorial/5.%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%83%A8%E7%BD%B2/%E5%9C%A8cpp%E4%B8%8B%E4%BD%BF%E7%94%A8tvm%E6%9D%A5%E9%83%A8%E7%BD%B2mxnet%E6%A8%A1%E5%9E%8B%E4%BB%A5insightface%E4%B8%BA%E4%BE%8B/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default"></span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/hyperdl-tutorial/6.%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%BE%E8%AE%A1/readme/">
            <span class="next-text nav-default"></span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="comments-gitment"></div>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/default.min.css" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/gitment.browser.min.js" crossorigin="anonymous"></script>
    <script type="text/javascript">
      var gitment = new Gitment({
        id: '0001-01-01 00:00:00 \x2b0000 UTC',
        title: '',
        link: decodeURI(location.href),
        desc: 'MTCNN优化和另类用法 MTCNN是目前应用十分广泛的基于级联的特定目标检测器，也是少数能在传统硬件上落地的检测器，当然其优势不光光仅仅用于人脸检测这个任务。在人脸这个任务上，在少数人脸\x26lt;5个人脸的情况下。其效能是第一梯队的水准。而且有着极大的优化空间（加上一些trick可以轻易的优化到极快的速度移动端 minSize60 60fps 1080p mt.）。而且其Alignment的准确率和精度也相对相对比较高，在工业界的人脸识别工作中，往往都采用MTCNN的点位来进行对齐。\n人脸跟踪是一项很重要的任务，cascade based检测模型，在人脸基数增大的同时，往往速度上容易爆炸，在工程应用中往往需要极致的速度。在有些效率比较低的ARM板子上，一些correlation filter tracker都不能取得很好的时效性。\nMTCNN的多任务特性为我们权衡这个问题提供的特别巧妙的方法。\nMTCNN的优化 MTCNN (Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks)是Kaipeng Zhang在2016年提出的Face Detector,也是基于Cascade CNN来改进的Face Detector。文章认为人脸检测任务中的 face bounding box regression 和 landmark 任务存在潜在关系，可以提高人脸检测效果。由于其多任务和全卷积的特性其速度要比Cascade CNN要快不少。由于MTCNN训练的Pipeline比较繁琐，需要一定的经验和调试，后继有人又提出了把Cascade pipeline联合起来训练的(Facecraft 和 xxx 两篇文章 都来自于商汤)。后来还有加Anchor 的做法 如 Anchor CNN 本文不再赘述。本文主要是从工程角度在FDDB下降不是特别多的情况下来改进和为了人脸识别而检测人脸的目的来加速MTCNN。\n基本原理 MTCNN基本原理是使用全卷积的P-Net在多尺度的待检图像上生成候选框，接着通过R-Net和O-Net来过滤。\nMTCNN的结构 我们可以看到其网络结构和Cascade CNN基本是一致的。由于文章的发表时间是2016年。一些较为modern的网络设计trick在当时也没有被提出。所以我们改进的空间还是有的。我们做了一些实验，也发现了MTCNN速度的瓶颈在哪。\n主要是以下几点\n 图片越大Pnet耗时也就越大。 人脸越多Onet和Rnet耗时越大。 噪点比较多的夜晚图像会导致Pnet误检测增多。  针对第一和第二个问题，我们选择优化网络结构，使之精度下降不太多的情况下，尽可能的减少计算量，第一个我们想到的是Mobilenet系列中的Depthwise卷积。\nDepthwise卷积 Depthwise卷积最初来源于Xception。其思路比较直接，先是对输入图的每个通道进行卷积，然后再由1x1卷积将他们合并起来，大量实验证明的这个操作基本可以等同于普通的Sptial卷积。并且在IO效率和性能不变的情况下，计算量降低9倍。我们可以利用这个思路替换Pnet和Rnet和Onet中的卷积操作使之速度有着大幅度提升。\n但是有时候即使加了Depthwise卷积在某些嵌入式环境下，效果仍然不是很好，达不到良好的效果。我们发现Depthwise卷积80-90%的计算量基本都被后面的1x1卷积占据了。这时我们想是否也可以把1x1卷积也用类似于Depthwise的分组卷积来替代，但是一旦把后面1x1卷积分组，组与组之间的信息就无法相互交流了，于是shuffle-channel的出现很好的解决了这个问题。\nshuffle-channel shuffle-channel来源于旷世的ShuffleNet。虽然这篇文章宣称的精度难以复现。但其shuffle-channel的思想是非常值得借鉴的。shuffle-channel的原理将特征的通道平均分到不同组里面。是之每个组卷积的时候能得到其他组的信息。起到了一个组之间通信的作用。\n我们做了一些实验来证明了本文论述的结果\n    sets-1 sets-2     MTCNN 21fps 11fps   MTCNN-dw 131fps 101fps   MTCNN-shuffle 220fps 135fps    其中 sets-1 数据集均为一张人脸，sets-2数据集为2-4张人脸的普通监控场景。测试框架是caffe。环境为Macbook 2015 r15 2.',
        owner: 'lflxp',
        repo: 'https:\/\/github.com\/lflxp\/lflxp.github.com',
        oauth: {
          client_id: '',
          client_secret: ''
        }
      });
      gitment.render('comments-gitment');
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/imsun/gitment">comments powered by gitment.</a></noscript>

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:382023823@qq.com" class="iconfont icon-email" title="email"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-twitter" title="twitter"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-facebook" title="facebook"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-google" title="google"></a>
      <a href="https://github.com/lflxp" class="iconfont icon-github" title="github"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-weibo" title="weibo"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-douban" title="douban"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-pocket" title="pocket"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-instagram" title="instagram"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-gitlab" title="gitlab"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="https://www.lflxp.cn/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2016 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">lflxp.cn 版权所有 ICP证：<a href='http://www.beian.miit.gov.cn' target='_blank'>渝ICP备17011066号-1</a></span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.min.js" integrity="sha256-jwCP0NAdCBloaIWTWHmW4i3snUNMHUNO+jr9rYd2iOI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.locales.min.js" integrity="sha256-ZwofwC1Lf/faQCzN7nZtfijVV6hSwxjQMwXL4gn9qU8=" crossorigin="anonymous"></script>
  <script><!-- NOTE: timeago.js uses the language code format like "zh_CN" (underscore and case sensitive) -->
    var languageCode = "zh-cn".replace(/-/g, '_').replace(/_(.*)/, function ($0, $1) {return $0.replace($1, $1.toUpperCase());});
    timeago().render(document.querySelectorAll('.timeago'), languageCode);
    timeago.cancel();  
  </script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', '渝ICP备17011066号-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
