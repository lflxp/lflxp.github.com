<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>爱像水墨青花</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="lflxp" /><meta name="description" content="私人私塾" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.62.2 with theme even" />


<link rel="canonical" href="https://www.lflxp.cn/" />
  <link href="https://www.lflxp.cn/index.xml" rel="alternate" type="application/rss+xml" title="爱像水墨青花" />
  <link href="https://www.lflxp.cn/index.xml" rel="feed" type="application/rss+xml" title="爱像水墨青花" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="爱像水墨青花" />
<meta property="og:description" content="私人私塾" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://www.lflxp.cn/" />

<meta itemprop="name" content="爱像水墨青花">
<meta itemprop="description" content="私人私塾"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="爱像水墨青花"/>
<meta name="twitter:description" content="私人私塾"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">琵琶</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">主页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">琵琶</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">主页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <section id="posts" class="posts">
    <article class="post">
  <header class="post-header">
    <h1 class="post-title"><a class="post-link" href="/post/hyperdl-tutorial/8.%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83/readme/"></a></h1>
    <div class="post-meta">
      <span class="post-time"> 0001-01-01 </span>
      
    </div>
  </header>
  
  <div class="post-content">
    <div class="post-summary">
      基础网络的训练 目前我们常用的神经网络，github上基本都具有较为丰富的训练、测试代码，我们这里选择几种常用，高效的网络推荐给大家，包括与之对应的github工程，涉及一些训练的技巧，旨在让大家能够复现出作者原始的精度。
我们这里主要介绍以下几个网络的训练与使用:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  1.MobileNet(分类网络)2.MnasNet(分类网络)3.MTCNN(单一物体检测网络)4.MobileNet-SSD(Single Shot 物体检测网络)5.CTPN(文字定位网络)6.insightface(人脸识别网络)7.VanillaCNN(人脸关键点回归网络)8.YOLO-V3(通用物体检测网络)9.DeepOCR(文字识别网络)  以上这些网络涵盖了日常使用网络设计到的大部分功能，一些相关的应用也可以通过这些网络的变通，修改进行试验。
1.MobileNet MobileNet是谷歌发布的第一代专为移动端设计的高效网络，其后续版本MobileNet-v2同样优秀，shicai yang大神已经给出了网络的pretrain model，以及caffe的训练、测试代码，利用该网络可以训练其他类似的分类任务，例如我们开源的鉴黄网络.
2.MnasNet MnasNet同样是谷歌发布的高效移动端分类网络，与Mobilenet不同之处在于网络的设计借助deepmind AI的能力，不是hand craft手动设计的网络，相比于mobilenet，速度快大约1.5倍，准确度提高将近两个点。我们同样复现了该网络，并且提供了该网络再标准ImageNet上的pretrain model，接近了官方的精度。连接地址：https://github.com/zeusees/Mnasnet-Pretrained-Model
3.MTCNN MTCNN是一个非常优秀的单一物体检测框架，可以用这个框架进行人脸、车辆、行人等单一物体的检测，该网络的主要问题在于单帧图像中包含多个物体时，检测速度下降严重。mtcnn的复现在github上有多个版本，包括caffe、keras、TensorFlow等，我们测试了不同版本，有一些存在问题，https://github.com/AITTSMD/MTCNN-Tensorflow 这个repo能够基本复现作者的精度，训练过程中，一定要注意正负样本保持1:3的比例。其实，mtcnn框架具有一些优化的方法和空间，包括用卷积替代polling，采用dw卷积等等，相关修改可以参考我们的文章: https://blog.csdn.net/Relocy/article/details/84075570 . 我们的工程师同样提供了一个优化的mtcnn模型：https://github.com/szad670401/Fast-MTCNN ，大家可以参考修改。
4.MobileNet-SSD SSD是Single Shot检测网络的代表结构，其速度快，单帧物体数量对检测速度影响不大，具有很好的工程化指导作用。Mobilenet跟SSD的结合，更能够提高网络的速度。Mobilenet-SSD可以参考：https://github.com/chuanqi305/MobileNet-SSD 这里有数据准备代码，以及网络的训练测试代码。我们采用这个网络进行了车牌检测的实验，效果也不错，能够完成单层、双层、蓝牌、黄牌、绿牌的检测，可以参见我们的博客：https://blog.csdn.net/lsy17096535/article/details/78687728 ，我们开源的车牌检测Mobilenet-SSD模型：https://github.com/zeusees/Mobilenet-SSD-License-Plate-Detection
5.CTPN 6.insightface insightface是一款高精度的开源人脸识别框架，在我们的测试中，insightface针对一般场景效果不错，“历史脸”效果稍差，有可能因为训练数据历史脸数据不足导致的，算法的作者guojia也将论文提交到了CVPR2019，期待他的好消息。大家可以在这里找到作者的实现：https://github.com/deepinsight/insightface 作者的框架基于MXNET，目前git上已经有基于TensorFlow、caffe等其他框架的实现，大家可以参考。大家在部署阶段，可以利用TVM部署该框架，速度快，也可以将模型转换到caffe model，部署到其他平台。TVM部署方法可以参考我们的博客：insightface模型的TVM框架部署
7.VanillaCNN VanillaCNN是针对香港中文大学人脸关键点定位网络TCDCN的一个复现，大家可以参考 https://github.com/ishay2b/VanillaCNN 。稠密人脸关键点定位(通常关键点50点以上)同样是一个回归问题，让网络能够通过对人脸边缘特征的提取，回归出准确的定位，这篇文章采用了多任务进行定位，取得了很好的效果，后来几年的的很多算法，在准确度上有提升，但是在速度上不具有优势。大家可以利用高效的网络结构提取特征并加速，取得更好的人脸关键点定位准确度和速度。大家在训练关键点定位的网络时，可以结合可视化的技术，将网络后面基层的feature map显示出来，观察网络对输入人脸边缘提取的效果，改进网络结构。
8.YOLO-V3 通用物体检测近年来也是研究人员关注的人们领域，从RBG、何凯明大神的RCNN，Fast RCNN，Faster RCNN，MASK RCNN等，Single Shot的Yolo系列、SSD等，以后后来的RetinaNet，我们对这一系列的网络都进行过测试，由于我们算法组在日常使用中主要考虑移动端的部署以及服务器端的效率，推荐了MobileNet-SSD跟YOLO-V3。我们对3000张行车记录仪标注图像以及2000张交通监控图片进行标注，分别在以上网络进行了测试，对于我们的图片，YOLO-V3表现最好，速度也是最快的一档。项目主页：https://pjreddie.
    </div>
    <div class="read-more">
      <a href="/post/hyperdl-tutorial/8.%E5%9F%BA%E7%A1%80%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%AD%E7%BB%83/readme/" class="read-more-link">阅读更多</a>
    </div>
  </div>
</article>

    <article class="post">
  <header class="post-header">
    <h1 class="post-title"><a class="post-link" href="/post/hyperdl-tutorial/9.%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/readme/"></a></h1>
    <div class="post-meta">
      <span class="post-time"> 0001-01-01 </span>
      
    </div>
  </header>
  
  <div class="post-content">
    <div class="post-summary">
      相关问题 说是面试题，并不是为了读者去利用这个去参加面试，只是为了一些图像算法相关问题的深入理解，这里面的一些问题，除了参考网上的解答，也包含了 部分我们自己的理解，不当之处欢迎指出。
1.CNN的特点以及优势 改变全连接为局部连接，这是由于图片的特殊性造成的（图像的一部分的统计特性与其他部分是一样的），通过局部连接和参数共享大范围的减少参数值。可以通过使用多个filter来提取图片的不同特征（多卷积核）。
CNN使用范围是具有局部空间相关性的数据，比如图像，自然语言，语音
1.局部连接：可以提取局部特征。2.权值共享：减少参数数量，因此降低训练难度（空间、时间消耗都少了）。 3.可以完全共享，也可以局部共享（比如对人脸，眼睛鼻子嘴由于位置和样式相对固定，可以用和脸部不一样的卷积核）4.降维：通过池化或卷积stride实现。5.多层次结构：将低层次的局部特征组合成为较高层次的特征。不同层级的特征可以对应不同任务。 2.deconv的作用 1.unsupervised learning： 重构图像2.CNN可视化：将conv中得到的feature map还原到像素空间，来观察特定的feature map对哪些pattern的图片敏感3.Upsampling：上采样。 3.dropout作用以及实现机制 (参考:https://blog.csdn.net/nini_coded/article/details/79302800) 1.dropout是指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃。注意是暂时，对于随机梯度下降来说，由于是随机丢弃，故而每一个mini-batch都在训练不同的网络。2.dropout是一种CNN训练过程中防止过拟合提高效果的方法3.dropout带来的缺点是可能减慢收敛速度：由于每次迭代只有一部分参数更新，可能导致梯度下降变慢4.测试时，需要每个权值乘以P 4.深度学习中有什么加快收敛/降低训练难度的方法： 1.瓶颈结构2.残差3.学习率、步长、动量4.优化方法5.预训练 5.什么造成过拟合，如何防止过拟合 1.data agumentation2.early stop3.参数规则化4.用更简单模型5.dropout6.加噪声7.预训练网络freeze某几层 6.LSTM防止梯度弥散和爆炸 LSTM用加和的方式取代了乘积，使得很难出现梯度弥散。但是相应的更大的几率会出现梯度爆炸，但是可以通过给梯度加门限解决这一问题 7.为什么很多做人脸的Paper会最后加入一个Local Connected Conv? 在一些研究成果中，作者通过实验表明：人脸在不同的区域存在不同的特征（眼睛／鼻子／嘴的分布位置相对固定），当不存在全局的局部特征分布时，Local-Conv更适合特征的提取。
8.神经网络权值初始化方式以及不同方式的区别? 权值初始化的方法主要有：常量初始化（constant）、高斯分布初始化（gaussian）、positive_unitball初始化、均匀分布初始化（uniform）、xavier初始化、msra初始化、双线性初始化（bilinear）
9.Convolution、 pooling、 Normalization是卷积神经网络中十分重要的三个步骤，分别简述Convolution、 pooling和Normalization在卷积神经网络中的作用。 10.dilated conv(空洞卷积)优缺点以及应用场景 基于FCN的语义分割问题中，需保持输入图像与输出特征图的size相同。若使用池化层，则降低了特征图size,需在高层阶段使用上采样，由于池化会损失信息，所以此方法会影响导致精度降低；若使用较小的卷积核尺寸，虽可以实现输入输出特征图的size相同，但输出特征图的各个节点感受野小；若使用较大的卷积核尺寸，由于需增加特征图通道数，此方法会导致计算量较大；所以，引入空洞卷积(dilatedconvolution),在卷积后的特征图上进行0填充扩大特征图size，这样既因为有卷积核增大感受野，也因为0填充保持计算点不变。 11.判别模型和生成模型解释 监督学习方法又分生成方法（Generative approach）和判别方法（Discriminative approach），所学到的模型分别称为生成模型（Generative Model）和判别模型（Discriminative Model）。
    </div>
    <div class="read-more">
      <a href="/post/hyperdl-tutorial/9.%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/readme/" class="read-more-link">阅读更多</a>
    </div>
  </div>
</article>

    <article class="post">
  <header class="post-header">
    <h1 class="post-title"><a class="post-link" href="/post/hyperdl-tutorial/9.%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%981-5/"></a></h1>
    <div class="post-meta">
      <span class="post-time"> 0001-01-01 </span>
      
    </div>
  </header>
  
  <div class="post-content">
    <div class="post-summary">
      1.CNN的卷积核是单层还是多层的？
描述网络模型中某层的厚度，通常用名词通道channel数或者特征图feature map数。不过人们更习惯把作为数据输入的前层的厚度称之为通道数（比如RGB三色图层称为输入通道数为3），把作为卷积输出的后层的厚度称之为特征图数。
卷积核的厚度H, 一般等于前层厚度M(输入通道数或feature map数). 特殊情况M &gt; H。
卷积核的个数N, 一般等于后层厚度(后层feature maps数，因为相等所以也用N表示)。
卷积核通常从属于后层，为后层提供了各种查看前层特征的视角，这个视角是自动形成的。
卷积核厚度等于1时为2D卷积，对应平面点相乘然后把结果加起来，相当于点积运算；
卷积核厚度大于1时为3D卷积，每片分别平面点求卷积，然后把每片结果加起来，作为3D卷积结果；
1x1卷积属于3D卷积的一个特例，有厚度无面积, 直接把每片单个点乘以权重再相加。
归纳之，卷积的意思就是把一个区域，不管是一维线段，二维方阵，还是三维长方块，全部按照卷积核的维度形状，对应逐点相乘再求和，浓缩成一个标量值也就是降到零维度，作为下一层的一个feature map的一个点的值！ 可以比喻一群渔夫坐一个渔船撒网打鱼，鱼塘是多层水域，每层鱼儿不同。 船每次移位一个stride到一个地方，每个渔夫撒一网，得到收获，然后换一个距离stride再撒，如此重复直到遍历鱼塘。 A渔夫盯着鱼的品种，遍历鱼塘后该渔夫描绘了鱼塘的鱼品种分布； B渔夫盯着鱼的重量，遍历鱼塘后该渔夫描绘了鱼塘的鱼重量分布； 还有N-2个渔夫，各自兴趣各干各的； 最后得到N个特征图，描述了鱼塘的一切！
2.什么是卷积？
对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的多个权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐个元素相乘再求和）的操作就是所谓的『卷积』操作，也是卷积神经网络的名字来源。
3.什么是CNN的池化
池化，简言之，即取区域平均或最大，如下图所示（图引自cs231n）
上图所展示的是取区域最大，即上图左边部分中 左上角2x2的矩阵中6最大，右上角2x2的矩阵中8最大，左下角2x2的矩阵中3最大，右下角2x2的矩阵中4最大，所以得到上图右边部分的结果：6 8 3 4。
4.简述下什么是生成对抗网络？
GAN之所以是对抗的，是因为GAN的内部是竞争关系，一方叫generator，它的主要工作是生成图片，并且尽量使得其看上去是来自于训练样本的。另一方是discriminator，其目标是判断输入图片是否属于真实训练样本。 更直白的讲，将generator想象成假币制造商，而discriminator是警察。generator目的是尽可能把假币造的跟真的一样，从而能够骗过discriminator，即生成样本并使它看上去好像来自于真实训练样本一样。
5.请介绍下tensorflow的计算图
Tensorflow是一个通过计算图的形式来表述计算的编程系统，计算图也叫数据流图，可以把计算图看做是一种有向图，Tensorflow中的每一个节点都是计算图上的一个Tensor, 也就是张量，而节点之间的边描述了计算之间的依赖关系(定义时)和数学操作(运算时)。如下两图表示：
a=x*y;
b=a+z;
c=tf.reduce_sum(b);
    </div>
    <div class="read-more">
      <a href="/post/hyperdl-tutorial/9.%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%981-5/" class="read-more-link">阅读更多</a>
    </div>
  </div>
</article>

    <article class="post">
  <header class="post-header">
    <h1 class="post-title"><a class="post-link" href="/post/hyperdl-tutorial/9.%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%9811-15/"></a></h1>
    <div class="post-meta">
      <span class="post-time"> 0001-01-01 </span>
      
    </div>
  </header>
  
  <div class="post-content">
    <div class="post-summary">
      11.relu为何好过sigmoid和tanh？
先看sigmoid、tanh和RelU的函数图：
第一，采用sigmoid等函数，算激活函数时（指数运算），计算量大，反向传播求误差梯度时，求导涉及除法和指数运算，计算量相对大，而采用Relu激活函数，整个过程的计算量节省很多。
第二，对于深层网络，sigmoid函数反向传播时，很容易就会出现梯度消失的情况（在sigmoid接近饱和区时，变换太缓慢，导数趋于0，这种情况会造成信息丢失），这种现象称为饱和，从而无法完成深层网络的训练。而ReLU就不会有饱和倾向，不会有特别小的梯度出现。
第三，Relu会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生（以及一些人的生物解释balabala）。当然现在也有一些对relu的改进，比如prelu，random relu等，在不同的数据集上会有一些训练速度上或者准确率上的改进。
12.为什么LSTM中既存在tanh和sigmoid，而不同意采用一样的。
sigmoid 用在了各种gate上，产生0~1之间的值，这个一般只有sigmoid最直接了。 tanh 用在了状态和输出上，是对数据的处理，这个用其他激活函数或许也可以。
13.如何解决RNN梯度消失和弥散的情况？
为了解决梯度爆炸问题，Thomas Mikolov首先提出了一个简单的启发性的解决方案，就是当梯度大于一定阈值的的时候，将它截断为一个较小的数。具体如算法1所述： 算法：当梯度爆炸时截断梯度（伪代码）
下图可视化了梯度截断的效果。它展示了一个小的rnn（其中W为权值矩阵，b为bias项）的决策面。这个模型是一个一小段时间的rnn单元组成；实心箭头表明每步梯度下降的训练过程。当梯度下降过程中，模型的目标函数取得了较高的误差时，梯度将被送到远离决策面的位置。截断模型产生了一个虚线，它将误差梯度拉回到离原始梯度接近的位置。
梯度爆炸，梯度截断可视化 为了解决梯度弥散的问题，我们介绍了两种方法。第一种方法是将随机初始化改为一个有关联的矩阵初始化。第二种方法是使用ReLU（Rectified Linear Units）代替sigmoid函数。ReLU的导数不是0就是1.因此，神经元的梯度将始终为1，而不会当梯度传播了一定时间之后变小。
14.什么样的资料集不适合深度学习？
1、数据集太小，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势。
2、数据集没有局部相关特性，目前深度学习表现比较好的领域主要是图像／语音／自然语言处理等领域，这些领域的一个共性是局部相关性。图像中像素组成物体，语音信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱，表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算法进行处理。举个例子：预测一个人的健康状况，相关的参数会有年龄、职业、收入、家庭状况等各种元素，将这些元素打乱，并不会影响相关的结果。
15.如何解决梯度消失和梯度爆炸？
（1）梯度消失： 根据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都小于1的话，那么即使这个结果是0.99，在经过足够多层传播之后，误差对输入层的偏导会趋于0 可以采用ReLU激活函数有效的解决梯度消失的情况，也可以用Batch Normalization解决这个问题。关于深度学习中 Batch Normalization为什么效果好？参见：https://www.zhihu.com/question/38102762
（2）梯度膨胀 ：根据链式法则，如果每一层神经元对上一层的输出的偏导乘上权重结果都大于1的话，在经过足够多层传播之后，误差对输入层的偏导会趋于无穷大 可以通过RELU激活函数来解决，或用Batch Normalization解决这个问题。
    </div>
    <div class="read-more">
      <a href="/post/hyperdl-tutorial/9.%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%9811-15/" class="read-more-link">阅读更多</a>
    </div>
  </div>
</article>

    <article class="post">
  <header class="post-header">
    <h1 class="post-title"><a class="post-link" href="/post/hyperdl-tutorial/9.%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%9816-20/"></a></h1>
    <div class="post-meta">
      <span class="post-time"> 0001-01-01 </span>
      
    </div>
  </header>
  
  <div class="post-content">
    <div class="post-summary">
      16.CNN常用的几个简单模型
见基础网络
17.梯度爆炸会引发什么？
在深度多层感知机网络中，梯度爆炸会引起网络不稳定，最好的结果是无法从训练数据中学习，而最坏的结果是出现无法再更新的 NaN 权重值。 梯度爆炸导致学习过程不稳定。—《深度学习》，2016. 在循环神经网络中，梯度爆炸会导致网络不稳定，无法利用训练数据学习，最好的结果是网络无法学习长的输入序列数据。
有很多方法可以解决梯度爆炸问题，本节列举了一些最佳实验方法。
1. 重新设计网络模型 在深度神经网络中，梯度爆炸可以通过重新设计层数更少的网络来解决。 使用更小的批尺寸对网络训练也有好处。 在循环神经网络中，训练过程中在更少的先前时间步上进行更新（沿时间的截断反向传播，truncated Backpropagation through time）可以缓解梯度爆炸问题。
2. 使用 ReLU 激活函数 在深度多层感知机神经网络中，梯度爆炸的发生可能是因为激活函数，如之前很流行的 Sigmoid 和 Tanh 函数。 使用 ReLU 激活函数可以减少梯度爆炸。采用 ReLU 激活函数是最适合隐藏层的新实践。
3. 使用长短期记忆网络 在循环神经网络中，梯度爆炸的发生可能是因为某种网络的训练本身就存在不稳定性，如随时间的反向传播本质上将循环网络转换成深度多层感知机神经网络。 使用长短期记忆（LSTM）单元和相关的门类型神经元结构可以减少梯度爆炸问题。 采用 LSTM 单元是适合循环神经网络的序列预测的最新最好实践。
4. 使用梯度截断（Gradient Clipping） 在非常深且批尺寸较大的多层感知机网络和输入序列较长的 LSTM 中，仍然有可能出现梯度爆炸。如果梯度爆炸仍然出现，你可以在训练过程中检查和限制梯度的大小。这就是梯度截断。 处理梯度爆炸有一个简单有效的解决方案：如果梯度超过阈值，就截断它们。 ——《Neural Network Methods in Natural Language Processing》，2017. 具体来说，检查误差梯度的值是否超过阈值，如果超过，则截断梯度，将梯度设置为阈值。 梯度截断可以一定程度上缓解梯度爆炸问题（梯度截断，即在执行梯度下降步骤之前将梯度设置为阈值）。 ——《深度学习》，2016. 在 Keras 深度学习库中，你可以在训练之前设置优化器上的 clipnorm 或 clipvalue 参数，来使用梯度截断。 默认值为 clipnorm=1.0 、clipvalue=0.5。详见：https://keras.io/optimizers/。
5. 使用权重正则化（Weight Regularization） 如果梯度爆炸仍然存在，可以尝试另一种方法，即检查网络权重的大小，并惩罚产生较大权重值的损失函数。该过程被称为权重正则化，通常使用的是 L1 惩罚项（权重绝对值）或 L2 惩罚项（权重平方）。 对循环权重使用 L1 或 L2 惩罚项有助于缓解梯度爆炸。 ——On the difficulty of training recurrent neural networks，2013.
    </div>
    <div class="read-more">
      <a href="/post/hyperdl-tutorial/9.%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%9816-20/" class="read-more-link">阅读更多</a>
    </div>
  </div>
</article>

    </section>
  
  <nav class="pagination">
    <a class="prev" href="/page/2/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text">上一页</span>
      </a>
    <a class="next" href="/page/4/">
        <span class="next-text">下一页</span>
        <i class="iconfont icon-right"></i>
      </a>
  </nav>
        </div>
        

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:382023823@qq.com" class="iconfont icon-email" title="email"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-twitter" title="twitter"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-facebook" title="facebook"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-google" title="google"></a>
      <a href="https://github.com/lflxp" class="iconfont icon-github" title="github"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-weibo" title="weibo"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-douban" title="douban"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-pocket" title="pocket"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-instagram" title="instagram"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-gitlab" title="gitlab"></a>
      <a href="https://www.lflxp.cn" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="https://www.lflxp.cn/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> 本站总访问量 <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 次 </span>
      <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> 本站总访客数 <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> 人 </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2016 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">lflxp.cn 版权所有 ICP证：<a href='http://www.beian.miit.gov.cn' target='_blank'>渝ICP备17011066号-1</a></span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.min.js" integrity="sha256-jwCP0NAdCBloaIWTWHmW4i3snUNMHUNO+jr9rYd2iOI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/timeago.js@3.0.2/dist/timeago.locales.min.js" integrity="sha256-ZwofwC1Lf/faQCzN7nZtfijVV6hSwxjQMwXL4gn9qU8=" crossorigin="anonymous"></script>
  <script><!-- NOTE: timeago.js uses the language code format like "zh_CN" (underscore and case sensitive) -->
    var languageCode = "zh-cn".replace(/-/g, '_').replace(/_(.*)/, function ($0, $1) {return $0.replace($1, $1.toUpperCase());});
    timeago().render(document.querySelectorAll('.timeago'), languageCode);
    timeago.cancel();  
  </script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', '渝ICP备17011066号-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
